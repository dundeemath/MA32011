[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA32009",
    "section": "",
    "text": "Preface\nWelcome to MA42002 Mathematical Biology I.\nMy name is Philip Murray and I am the module lead."
  },
  {
    "objectID": "index.html#how-to-contact-me",
    "href": "index.html#how-to-contact-me",
    "title": "MA32009",
    "section": "How to contact me?",
    "text": "How to contact me?\n\nemail: pmurray@dundee.ac.uk\noffice: G11, Fulton Building"
  },
  {
    "objectID": "index.html#lecture-notes",
    "href": "index.html#lecture-notes",
    "title": "MA32009",
    "section": "Lecture notes",
    "text": "Lecture notes\nYou can find lecture notes for the module on this page. If you would like a pdf this can be easily generated by clicking on the pdf link on the top left of the webpages. I will occasionally edit/update the notes we proceed through lectures. If you spot any errors, typos or omissions please let me know."
  },
  {
    "objectID": "index.html#reading",
    "href": "index.html#reading",
    "title": "MA32009",
    "section": "Reading",
    "text": "Reading\nMathematical Biology I, Murray (2002)\nEsswential Mathemtical Biology Britton and Britton (2003)\nMathematical models in Biology Edelstein-Keshet (2005)"
  },
  {
    "objectID": "index.html#python-codes",
    "href": "index.html#python-codes",
    "title": "MA32009",
    "section": "Python codes",
    "text": "Python codes\nI have provided Python codes for most of the figures in the notes (you can unfold code section by clicking `Code’). Note that the Python code does not appear in the pdf.\nMany of you have taken the Introduction to Programming module at Level 2 and have therefore some experience using Python. I strongly encourage you to use the provided codes as a tool to play around with numerical solutions of the various models that we will be working on. The codes should run as standalone Python codes.\nI have also provided some examples of how to use Python as a symbolic calculator. This uses a Python library called sympy and is quite similar to Maple."
  },
  {
    "objectID": "index.html#assessment",
    "href": "index.html#assessment",
    "title": "MA32009",
    "section": "Assessment",
    "text": "Assessment\n\nFinal exam (80 %)\n2 class tests (8.5 % each), Week 6 and 10\n3 quizes (1 % each), Week 2,4 and 8"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "MA32009",
    "section": "References",
    "text": "References\n\n\n\n\nBritton, Nicholas F, and NF Britton. 2003. Essential Mathematical Biology. Vol. 453. Springer.\n\n\nEdelstein-Keshet, Leah. 2005. Mathematical Models in Biology. SIAM.\n\n\nMurray, J. D. 2002. Mathematical Biology i: An Introduction. Springer."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-general-model-for-a-single-population-in-discrete-time",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-general-model-for-a-single-population-in-discrete-time",
    "title": "1  Single species population dynamics",
    "section": "1.1 A general model for a single population in discrete time",
    "text": "1.1 A general model for a single population in discrete time\nLet \\(t\\) be an independent variable representing time and \\(N_t\\) be a dependent variable representing the size of the population of a given species at time \\(t\\).\nConsider the first order difference equation \\[\nN_{t+1}=N_tf(N_t)=H(N_t),\n\\tag{1.1}\\] where \\(f(N_t)\\) is a function that defines the per capita growth rate. The function \\(H(N_t)\\) describes the total (net) growth rate.\nGiven some initial condition \\(N_0\\) defined such that \\[\nN_{t=0}=N_0,\n\\] the goal of this section is to develop a range of techniques that allow us to analyse the behaviour of Equation 1.1 for a given \\(H\\).\nFinally, note that many of you were introduced to difference equations in the module MA21003 Discrete Mathematics. It is recommended that you revisit the section on Discrete Difference Equations."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#the-malthusian-model",
    "href": "MA32009-SinglePopDiscreteTimea.html#the-malthusian-model",
    "title": "1  Single species population dynamics",
    "section": "1.2 The Malthusian model",
    "text": "1.2 The Malthusian model\nPerhaps the simplest form for equation Equation 1.1 is when the net per capita growth rate is a constant.\nLet \\(b\\) be the per capita growth rate and \\(d\\) the per capita death rate with \\(b\\) and \\(d\\) both positive real constants.\nHence, a population of size \\(N_t\\) at time \\(t\\) will grow by \\[\nbN_t\n\\] over the course of the next iteration and decay by\n\\[\ndN_t.\n\\] Therefore the population size at time \\(t+1\\) is \\[\nN_{t+1}=N_t + bN_t - dN_t=rN_t,\n\\tag{1.2}\\] where the parameter \\(r=1+b-d\\) is known as the net growth rate.\nGiven the initial condition \\(N_0\\), equation Equation 1.2 can be solved recursively as follows:\n\\[\nN_1=rN_0,\nN_2=r(N_1)=r^2N_0,   \nN_3=rN_2=r^3N_0, ...,    \nN_t=r^tN_0.\n\\] Hence for the case of Malthusian growth, the size of the population can be explicitly calculated for all \\(t\\).\nIn Figure 1.1 a numerical solution of the model is computed for different values of the parameter \\(r\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=3.0\nr=0.5\nr_2=1.5\n\ndef rhs(x,par):\n  r=par\n  f=r*x\n  return f\n\ndef SolveSingleDiff(t,rhs,N_0,par):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],par) \n  return N\n\nN=SolveSingleDiff(t,rhs,N_0,r)\nN_2=SolveSingleDiff(t,rhs,N_0,r_2)\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(t, N)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.1: A plot of the Malthusian model solution when (a) \\(r\\)=0.5 and (b) \\(r\\)=1.5.\n\n\n\n\nCan you describe the behaviour of the Malthusian model? How does it depend on the value of the parameter \\(r\\)?\nQualitative analyses allows us to categorise solution behaviours into different cases. For example, note that the behaviour of the population at large \\(t\\) is governed by the magnitude of the parameter \\(r\\).\nAs \\(t\\rightarrow \\infty\\)\n\\[\nN \\rightarrow\n\\left\\{\n\\begin{array}{ll}\n\\infty & r&gt;1  \\\\\nN_0& r=1  \\\\  \n0 & r&lt;1.     \n\\end{array} \\right.\n\\]\nIn Figure 1.1 solutions in each of the (nontrivial) parameter regimes are plotted. When \\(r&lt;1\\) the population tends to zero and when \\(r&gt;1\\) the population explodes.\nWhilst the simplicity of the Malthusian model allows us to calculate explicit solutions that yield insight into how the processes of birth and death combine to give either net growth or net reduction in population size, an obvious flaw with this model is that it displays unbounded growth for \\(r&gt;1\\). In most biological systems, other effects, such as competition for resources or predation, will tend to limit a population’s size. In single species population models, these effects are accounted for phenomenologically by introducing nonlinear terms into the function \\(f\\)."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-motivating-example-of-a-nonlinear-model---the-ricker-model",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-motivating-example-of-a-nonlinear-model---the-ricker-model",
    "title": "1  Single species population dynamics",
    "section": "1.3 A motivating example of a nonlinear model - The Ricker model",
    "text": "1.3 A motivating example of a nonlinear model - The Ricker model\nMany models of population dynamics in discrete time were initially developed to study fisheries. Well-studied examples include the Beverton Holt model \\[\nN_{t+1}=\\frac{rN_t}{1+\\frac{N_t}{K}},\n\\] the Hassell model \\[\nN_{t+1}=\\frac{rN_t}{(1+\\frac{N_t}{K})^b},\n\\] and the Ricker model \\[\nN_{t+1}=N_te^{r(1-\\frac{N_t}{K})}.\n\\] where \\(r\\), \\(K\\) and \\(b\\) are positive parameters. Below we consider the Ricker model which was initially used to study Canadian sockeye salmon population dynamics.\n\n1.3.1 Model development\nOne way to capture a decreased growth rate at high densities, is to assume that the per capita growth rate is an exponentially decreasing function of population density, i.e.  \\[\nf(N_t)=e^{r(1-\\frac{N_t}{K})},\n\\] where \\(r\\) is a growth rate and \\(K\\) a carrying capacity (both positive constants). Hence the governing equation is \\[\nN_{t+1}=N_te^{r(1-\\frac{N_t}{K})}.\n\\tag{1.3}\\] Note that as the population size gets large (\\(N_t\\gg K\\)), the growth rate tends to zero but that for small populations \\(N_t\\ll K\\) the growth rate is approximately constant. This is the Ricker model.\nNote that the model is nonlinear and does not have an explicit solution.\n\n\n1.3.2 Computational solutions\nAfter directly computing numerical solutions of the Ricker model for different values of the parameter \\(r\\), the data in Figure 1.2 were obtained.\nNote that model behaviour changes drastically as the parameter \\(r\\) varies. For instance,\n\nwhen \\(r=0.5\\) (Figure 1.2 (a)), the solution monotonically approaches the value \\(2\\),\nwhen \\(r=1.5\\) (Figure 1.2 (b)) it approaches two in an oscillatory manner; and\nwhen \\(r=2.5\\) (Figure 1.2 (c)) it oscillates around two.\n\nThe above numerical results raise the following questions:\n\ncan we develop tools that allow us to qualitatively describe how the model solutions depend on model parameters?\nare the there certain families of solutions with qualitatively similar behaviours?\nhow do such families of solutions depend on model parameters?\n\nWe will return to analysis of the Ricker model in Worksheet 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr_1=0.5\nr_2=1.5\nr_3=2.5\nK=2.0\n\nT=20\nt = np.arange(0, T, 1)\nN_1 = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\nN_3 = np.zeros_like(t,dtype=float)\n\ndef rhs(x,par):\n  r=par[0]\n  K=par[1]\n  f=x*np.exp(r*(1-x/K))\n  return f\n\n\n\nN_1=SolveSingleDiff(t,rhs,N_0,[r_1,K])\nN_2=SolveSingleDiff(t,rhs,N_0,[r_2,K])\nN_3=SolveSingleDiff(t,rhs,N_0,[r_3,K])\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.2: A plot of numerical solutions of the Ricker model. (a)r=0.5. (b) r=1.5. (c) r=2.5."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#general-techniques-for-analysing-nonlinear-difference-equations",
    "href": "MA32009-SinglePopDiscreteTimea.html#general-techniques-for-analysing-nonlinear-difference-equations",
    "title": "1  Single species population dynamics",
    "section": "1.4 General techniques for analysing nonlinear difference equations",
    "text": "1.4 General techniques for analysing nonlinear difference equations\nIn this section we develop techniques that will be used to analyse first order, discrete-time models of the form \\[\nN_{t+1}=N_t f(N_t)=H(N_t).\n\\tag{1.4}\\]\n\n1.4.1 Computational solutions\nPerhaps the most obvious way to investigate an equation of the form of Equation 1.4 is to iteratively compute \\(N_t\\) over a prescribed time range.\nHence given some initial population \\(N_0\\), the solution set \\(\\{N_0,N_1,N_2,...,N_T\\}\\) is computed up to some end time \\(T\\). Such an approach provides a numerical solution for a given parameter set and initial condition. However, it does not provide much insight into the general behaviour of model.\n\n\n1.4.2 Fixed points\nWe define \\(N^*\\) to be a fixed point of Equation 1.4 if and only if \\[\nN^*=N^*f(N^*)=H(N^*).\n\\] Hence the fixed points can be identified by solving an algebraic equation.\n\n\n1.4.3 Linear stability\nBy linearising about the identified fixed points using a Taylor series expansion, it can be determined whether or not small perturbations around the fixed point grow or decay in subsequent iterations.\nMaking a change of dependent variables \\[\nN_t=N^*+\\hat{N_t},\n\\] Equation 1.4 transforms upon substitution to \\[\nN^*+\\hat{N}_{t+1} =  H(N^*+\\hat{N}_t).\n\\]\nTaylor expanding the right-hand side yields \\[\nN^*+\\hat{N}_{t+1}= H(N^*)+H'(N^*)\\hat{N}_t + h.o.t. .\n\\]\nNoting that at the fixed point \\[\nN^*= H(N^*),\n\\] cancellation yields \\[\n\\hat{N}_{t+1} = H'(N^*)\\hat{N}_t + h.o.t.\n\\] Hence considering only small perturbations about the fixed point, the leading order behaviour of the perturbation is governed by \\[\n\\hat{N}_{t} = (H'(N^*))^t\\hat{N}_0.\n\\]\nHence the linear stability of the fixed point is governed by the sign and magnitude of the term \\(H'(N^*)\\). If \\[\n|H'(N^*)| &gt;1,\n\\] the fixed point is unstable. Otherwise it it stable.\n\n\n1.4.4 Cobwebbing and linear stability\nA cobweb diagram allows solutions of a first order difference equation to be sketched without explicitly solving.\n\n1.4.4.1 An algorithm for generating a cobweb diagram\nThe cobweb diagram is created as follows:\n\nPlot the \\(t^{th}\\) iterate, \\(N_t\\), on the \\(x\\) axis and the \\(t+1^{st}\\), \\(N_{t+1}\\) on the \\(y\\) axis.\nSketch the net growth rate function \\(H(N_t)\\).\nSketch the line \\(N_{t+1}=N_t\\).\nNote any intersections between the straight line and the graph of \\(H(N_t)\\) are fixed points.\nPlot the first point \\((N_0, H(N_0))\\) on the cobweb diagram.\nPlot a horizontal line between \\((N_0, H(N_0))\\) and \\((H(N_0),H(N_0))\\). Note \\(N_1=H(N_0)\\).\nPlot a vertical line between \\((N_1,N_1)\\) and \\((N_1,H(N_1))\\). *Repeat steps 6 and 7.\n\nPlotting cobweb diagrams in the vicinity of a fixed point \\(N^*\\) for different values of \\(H'(N^*)\\) allows us to see graphically how the derivative of the right-hand side affects linear stability of a fixed point (see Figure 1.3). In particular,\n\nwhen \\(H'(N^*)&gt;1\\), the fixed point is monotonically unstable;\nwhen \\(0&lt;H'(N^*)&lt;1\\), the fixed point is monotonically stable;\nwhen \\(-1&lt;H'(N^*)&lt;0\\), the fixed point is oscillatory stable;\nwhen \\(H'(N^*)=-1\\), the fixed point is oscillatory; and\nwhen \\(H'(N^*)&lt;-1\\), the fixed point is oscillatory unstable.\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=2.4\nr=0.5\nr_2=1.5\nN_max=2.5\nN_min=1.5\ndef rhs(x,r):\n  f=r*x+1\n  return f\n\ndef SolveSingleDiffAndCobweb(t,rhs,N_0,r):\n  N = np.zeros_like(t,dtype=float)\n  N[0]=N_0\n\n\n  num_time_steps=t.shape[0]\n\n  CobwebSol=np.zeros((2*num_time_steps,2))\n  CobwebSol[0,0]=N_0\n  CobwebSol[0,1]=rhs(N_0,r)\n  CobwebSol[1,0]=CobwebSol[0,1]\n  CobwebSol[1,1]=CobwebSol[0,1]\n\n  for i in t:\n    if i&gt;0:\n      N[i]=rhs(N[i-1],r) \n\n      sol_temp=N[i-1]\n      rhs_temp=rhs(sol_temp,r)\n      CobwebSol[2*i,0]=sol_temp\n      CobwebSol[2*i,1]=rhs_temp\n      CobwebSol[2*i+1,0]=rhs_temp\n      CobwebSol[2*i+1,1]=rhs_temp\n  return N, CobwebSol\n\nN,CobwebSol=SolveSingleDiffAndCobweb(t,rhs,N_0,r)\n\nN_plot=np.linspace(N_min,N_max,100)\nH_N_plot=rhs(N_plot,r)\n\nfig, ax = plt.subplots(3,2)\nax[0,0].plot([N_min, N_max], [N_min, N_max])\nax[0,1].plot([N_min, N_max], [N_min, N_max])\nax[0,1].plot(N_plot, H_N_plot)\nax[1,0].plot([N_min, N_max], [N_min, N_max])\nax[1,0].plot(N_plot, H_N_plot)\nax[1,0].plot(CobwebSol[0,0], CobwebSol[0,1],'*')\nax[1,1].plot([N_min, N_max], [N_min, N_max])\nax[1,1].plot(N_plot, H_N_plot)\nax[1,1].plot(CobwebSol[0:5,0], CobwebSol[0:5,1])\nax[2,0].plot([N_min, N_max], [N_min, N_max])\nax[2,0].plot(N_plot, H_N_plot)\nax[2,0].plot(CobwebSol[0:7,0], CobwebSol[0:7,1])\nax[2,1].plot([N_min, N_max], [N_min, N_max])\nax[2,1].plot(N_plot, H_N_plot)\nax[2,1].plot(CobwebSol[:,0], CobwebSol[:,1])\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.3: Generating a cobweb plot.\n\n\n\n\n\n\n\n1.4.5 Bifurcation diagrams\nA bifurcation is a qualitative change in solution behaviour (either a change in the number of fixed points or their stability). A bifurcation diagram is a compact means of describing bifurcations as a function of model parameters. Usually, the fixed point value of the population (i.e. \\(N^*\\)) is plotted against a model parameter of interest. From this diagram one can immediately see how the number of fixed points and their stability changes as a given parameter increases.\n\n\n1.4.6 Perform a qualitative analysis on the Matlhusian model\nLet’s work through the various concepts introduced above using the Malthusian model (Equation 1.2).\nThe fixed points satisfy \\[\nN^*=rN^*.\n\\] As \\(r&gt;0\\) the only solution is \\(N^*=0\\).\nIn this case \\[\nH'(N_t)=r.\n\\] Hence the linear stability of the solution depends on the value of the parameter \\(r\\) For \\(r&gt;1\\) the fixed point \\(N^*=0\\) is monotonically unstable. For \\(r&lt;1\\) the fixed point \\(N^*=0\\) is monotonically unstable. As expected this result is consistent with the simulation results in Figure 1.1.\nFor cobweb diagram:\n\nSketch axes and label with \\(N_t\\) and \\(N_{t+1}\\).\nFrom linear stablity analysis note there are two qualitatively distinct cases (\\(r&lt;1\\) and \\(r&gt;1\\)). We will need a cobweb diagram for each case.\nCase 1: graph the function \\(H(N_t)\\). In this case it is the straight line \\(N_{t+1}=rN_t\\) with \\(r&lt;1\\).\nCase 2: graph the function \\(H(N_t)\\). In this case it is the straight line \\(N_{t+1}=rN_t\\) with \\(r&gt;1\\).\nFill in the cobwebbed trajectories with some arbitraily chosen initial condition.\nEstablish that behaviour of the cobweb is consistent with linear stability analysis.\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=3.0\nr=0.5\nr_2=1.5\nN_max=4.0\n\ndef rhs(x,r):\n  f=r*x\n  return f\n\nN,CobwebSol=SolveSingleDiffAndCobweb(t,rhs,N_0,r)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot=rhs(N_plot,r)\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(t, N)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(CobwebSol[:,0], CobwebSol[:,1])\nax[1].plot(CobwebSol[0,0], CobwebSol[0,1],'*')\nax[1].plot([0, N_max], [0, N_max])\nax[1].plot(N_plot, H_N_plot)\n\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.4: A cobweb plot of the Malthusian model solution when \\(r\\)=0.5. (a) Time series and (b) Cobweb diagrams.\n\n\n\n\nFor bifurcation diagram:\n\nWe will plot the value of fixed point against a parameter of interest. In this case \\(N^*\\) against \\(r\\).\nDeduce from fixed point and linear stability analysis whether there are any changes in solution behaviour as \\(r\\) varies (e.g. number of solution or their linear stability).\nIn this case the value of the fixed point is independent of \\(r\\) but the the linear stability changes at \\(r=1\\). This is a bifurcation.\nUse annotation to represent qualitative solution behaviour."
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-nonlinear-model-of-population-dynamics-in-discrete-time",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-nonlinear-model-of-population-dynamics-in-discrete-time",
    "title": "1  Single species population dynamics",
    "section": "1.5 A nonlinear model of population dynamics in discrete time",
    "text": "1.5 A nonlinear model of population dynamics in discrete time\nConsider a model of population growth given by \\[\nN_{t+1}=\\frac{\\gamma N_t}{1+N_t^2},\n\\tag{1.5}\\] where \\(\\gamma\\in \\Re^+\\) is the linear growth rate.\n\n1.5.1 The per capita growth rate\nNote that the per capita growth rate is described by the function \\[\nf(N_{t})=\\frac{\\gamma}{1+N_t^2}.\n\\] Hence at large populations the per capita growth rate tends to zero whilst for small populations it tends to \\(\\gamma\\). Hence so long as \\(\\gamma&gt;1\\) we will have net growth for small populations and net removal for large populations. The net growth rate is given by \\[\nH(N_{t})=\\frac{\\gamma N_t}{1+N_t^2}.\n\\]\n\n\n1.5.2 Numerical solution\nIn Figure 1.5 time series solution of the model are plotted for parameter values \\(\\gamma=0.5\\), \\(\\gamma=1.5\\), \\(\\gamma=2.5\\). Note qualitative changes in model behaviour in the different parameter regimes. Can you identify the fixed points? Are the solutions oscillatory?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\n\nN_0=3.0\ngam_1=0.5\ngam_2=1.5\ngam_3=2.5\n\ndef rhs(x,r):\n  f=r*x/(1+x**2)\n  return f\n\nN_1=SolveSingleDiff(t,rhs,N_0,gam_1)\nN_2=SolveSingleDiff(t,rhs,N_0,gam_2)\nN_3=SolveSingleDiff(t,rhs,N_0,gam_3)\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.5: Time series solution for (a) \\(g\\)=0.5 and (b) \\(g\\)=1.5 and (c) \\(g\\)=10.5.\n\n\n\n\n\n\n1.5.3 Fixed points\nThe fixed points of Equation 1.5 satisfy the algebraic equation \\[\nN^*=\\frac{\\gamma N^*}{1+{N^*}^2}\n\\] which has solutions \\[\nN^* = 0  \\ \\ \\ \\ \\textrm{and} \\ \\ \\ \\ N^*=\\sqrt{\\gamma-1}.\n\\]\n\n1.5.3.1 Parameter restrictions for biological validity\nIf \\(\\gamma&lt;1\\), there is only one biologically relevant fixed point. If \\(\\gamma &gt;1\\) there are two fixed-points, \\(N^*=0\\) and \\(N^*=\\sqrt{\\gamma-1}\\). Hence the value of the model parameter \\(\\gamma\\) qualitatively affects the behaviour and number of solutions.\n\n\n\n1.5.4 Linear stability analysis\nFor the given model we compute \\[\nH'(N_t)= \\frac{\\gamma}{1+N_t^2} + \\frac{-2 \\gamma N_t^2}{(1+N_t^2)^2}.\n\\]\n\n1.5.4.1 \\(N^*=0\\)\nThe stability of the fixed point \\(N^*=0\\) is determined by \\[\nH'(0)= \\gamma.\n\\] Hence if $ &lt;1$ the first fixed point is monotonically stable as \\(0&lt;H'(0) &lt; 1\\).\nWhen \\(\\gamma &gt; 1\\) the second fixed point becomes biologically relevant and the first fixed point becomes monotonically unstable.\n\n\n1.5.4.2 \\(N^*=\\sqrt{\\gamma-1}\\)\nThe stability of the second fixed point, \\(N^*=\\sqrt{\\gamma-1}\\), is determined by\n\\[\n\\begin{aligned}\nH'(\\sqrt{\\gamma-1})&= \\frac{\\gamma}{1+\\gamma-1} + \\frac{-2 \\gamma (\\gamma-1)}{(1+(\\gamma-1))^2}, \\\\\n&= \\frac{2}{\\gamma}-1.\n\\end{aligned}\n\\]\nHence if \\(N^*\\) were monotonically unstable,\n\\[\nH'(\\sqrt{\\gamma-1}) = \\frac{2}{\\gamma}-1 &gt;1,\n\\] and \\[\n\\gamma&lt;1.\n\\] As a necessary condition for the biological relevance of \\(N^*\\) is that \\(\\gamma&gt;1\\) we obtain a contradiction. Hence \\(N^*\\), if it is biologically relevant, cannot be monotonically unstable.\nSuppose \\(N^*\\) is monotonically stable. Then \\[\n0&lt;H'(N^*) &lt;1\n\\] which upon substitution yields \\[\n0&lt;\\frac{2}{\\gamma}-1  &lt;1.\n\\] Hence \\(1&lt;\\gamma&lt;2\\). Suppose \\(N^*\\) is oscillatory stable. Then \\[\n-1&lt;H'(N^*) &lt;0\n\\] which upon substitution yields \\[\n-1&lt;\\frac{2}{\\gamma}-1  &lt; 0.\n\\] Hence \\(\\gamma&gt;2\\). Hence the linear stability of the fixed point \\(N^*=\\sqrt{\\gamma-1}\\) depends on whether \\(\\gamma\\) lies in the range \\([0,1]\\), \\([1,2 ]\\) or \\([2,\\infty]\\).\n\n\n\n1.5.5 Cobweb diagrams\nIn Figure 1.6 cobweb diagrams illustrate model behaviour in the three different parameter regimes. Note that the cobweb diagrams can be sketched by hand, given an accurate enough sketch of the right-hand side function \\(H(N_t)\\). Note also that the cobweb diagrams are consistent with the linear stability analysis but that the linear approximation is only valid close to the equilibrium point.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.2\nr_1=0.5\nr_2=1.5\nr_3=2.5\nr_4=3.5\n\nN_max=4.0\n\ndef rhs(x,r):\n  f=r*x/(1+x**2)\n  return f\n\nN1,CobwebSol1=SolveSingleDiffAndCobweb(t,rhs,N_0,r_1)\nN2,CobwebSol2=SolveSingleDiffAndCobweb(t,rhs,N_0,r_2)\nN3,CobwebSol3=SolveSingleDiffAndCobweb(t,rhs,N_0,r_3)\nN4,CobwebSol4=SolveSingleDiffAndCobweb(t,rhs,N_0,r_4)\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,r_1)\nH_N_plot2=rhs(N_plot,r_2)\nH_N_plot3=rhs(N_plot,r_3)\nH_N_plot4=rhs(N_plot,r_4)\n\nfig, ax = plt.subplots(2,2)\n\nax[0,0].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0,0].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0,0].plot([0, N_max], [0, N_max])\nax[0,0].plot(N_plot, H_N_plot1)\n\nax[0,1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[0,1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[0,1].plot([0, N_max], [0, N_max])\nax[0,1].plot(N_plot, H_N_plot2)\n\nax[1,0].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[1,0].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[1,0].plot([0, N_max], [0, N_max])\nax[1,0].plot(N_plot, H_N_plot3)\n\nax[1,1].plot(CobwebSol4[:,0], CobwebSol4[:,1])\nax[1,1].plot(CobwebSol4[0,0], CobwebSol4[0,1],'*')\nax[1,1].plot([0, N_max], [0, N_max])\nax[1,1].plot(N_plot, H_N_plot4)\n\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.6: Cobweb diagrams for different values of gamma.\n\n\n\n\n\n\n1.5.6 Bifurcation diagram\nBifurcations at the critical values \\(\\gamma=1\\) and \\(\\gamma=2\\) are highlighted in the bifurcation diagram presented in Figure 1.7. Note that the bifurcation diagram allows classification of the different model behaviours in a single plot without explicitly calculating the solution to the model.\n\n\n1.5.7 Symbolic computation\nWe can use symbolic calculators to aid many of computations performed above. Below is an example using the Python library sympi.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\n\ngam_plot=np.linspace(0,4,100)\nN_star_1=0*np.zeros_like(gam_plot)\n\ngam_plot2=np.linspace(1,4,100)\nN_star_2=np.sqrt(gam_plot2-1)\n\nfig, ax = plt.subplots(1)\n\nax.plot(gam_plot,N_star_1)\nax.plot(gam_plot2,N_star_2)\n\n\nplt.xlabel('$\\gamma$')\nplt.ylabel('$N^*$')\nplt.show()\n\n\n\n\n\nFigure 1.7: A bifiurcation diagram.\n\n\n\n\nMany of the calculations can be aided by using a symbolic calculator.\n\n\nCode\nimport numpy as np\nimport sympy as sp\n\n# Define variables and constants\ngamma=sp.symbols(\"gamma\",real=True,nonnegative=True)\nN = sp.symbols(\"N\",real=True,nonnegative=True)\n\n# Define H\nH=gamma*N/(1+N**2)\n\n# Solve the FP equation\nfp=sp.solve(H-N,N,dict=True)\n\nprint(\"The FPs are:\")\nprint(fp)\n\n# Compute H prime\nH_p=H.diff(N)\n\n\nprint(\"The derivative of H is:\")\nprint(sp.simplify(H_p))\n\n\n# Evaluate derivative\n\nprint(\"The derivative evaluated at FP 1 is:\")\nsol1=fp[0][N]\nH_p_eval_0=sp.simplify(H_p.subs(N,sol1))\n\nprint(H_p_eval_0)\n\nprint(\"The derivative evaluated at FP 2 is:\")\nsol2=fp[2][N]\nH_p_eval_2=H_p.subs(N,sol2)\n\nprint(sp.simplify(H_p_eval_2))\n\n\nThe FPs are:\n[{N: 0}, {N: -sqrt(gamma - 1)}, {N: sqrt(gamma - 1)}]\nThe derivative of H is:\ngamma*(1 - N**2)/(N**2 + 1)**2\nThe derivative evaluated at FP 1 is:\ngamma\nThe derivative evaluated at FP 2 is:\n(2 - gamma)/gamma"
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#an-application---how-much-harvesting-can-a-population-sustain",
    "href": "MA32009-SinglePopDiscreteTimea.html#an-application---how-much-harvesting-can-a-population-sustain",
    "title": "1  Single species population dynamics",
    "section": "1.6 An application - how much harvesting can a population sustain?",
    "text": "1.6 An application - how much harvesting can a population sustain?\nModels of population dynamics can be used to study how interventions will affect population dynamics. Extending from the model developed in the previous example, a valid question might be what is the maximal rate of harvesting a fish stock can sustain without becoming extinct? ### Including a harvesting term Introducing a harvesting term at per capita harvesting rate \\(h\\), the governing model equation becomes \\[\nN_{t+1}=\\frac{\\gamma N_t}{1+N_t^2} - h N_t,\n\\tag{1.6}\\]\nand the questions we want to ask are: (i) does the introduction of harvesting change the dynamics of the system?; and (ii) what rate of harvesting such a population could withstand?\n\n1.6.1 Direct simulation\nBased on the previous analysis we consider the system in a parameter regime where without harvesting there is a stable fixed point (\\(\\gamma&gt;1\\)).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\n\nN_0=0.1\ngam=5.0\nh_1=0.1\nh_2=1.0\nh_3=3.0\n\ndef rhs(x,par):\n  r=par[0]\n  h=par[1]\n  f=r*x/(1+x**2)-h*x\n  return f\n\n\n\nN_1=SolveSingleDiff(t,rhs,N_0,[gam,h_1])\nN_2=SolveSingleDiff(t,rhs,N_0,[gam,h_2])\nN_3=SolveSingleDiff(t,rhs,N_0,[gam,h_3])\n\n\nfig, ax = plt.subplots(1,3)\nax[0].plot(t, N_1)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, N_2)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[2].plot(t, N_3)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nplt.show()\n\n\n\n\n\nFigure 1.8: Time series solution for (a) \\(g\\)=0.5 and (b) \\(g\\)=1.5 and (c) \\(g\\)=10.5.\n\n\n\n\nIn Figure 1.8 time series solutions at increasing harvesting rates (\\(h=0.1\\), \\(h=1\\), \\(h=3\\)) are presented. For low harvesting rates the system behaves almost identically to the no harvesting case but with an expected reduction in the fixed point value. However for intermediate harvesting the population undergoes oscillations. However, for further increased harvesting rates there appears again to be a stable fixed point.\nCan analysis of the model help us understand how/why changes in solutions occur?\n\n\n1.6.2 Fixed points\nThe fixed points of the system satisfy \\[\nN^*=\\frac{\\gamma N^*}{1+{N^*}^2} - h N^*.\n\\]\nHence the fixed points are \\[\nN^*=0\n\\]\nand \\[\nN^*=\\sqrt{\\frac{\\gamma}{1+h}-1}.\n\\]\nNote that harvesting lowers the population size of the non-zero fixed point (when it exists).\nCan we deduce a condition that must hold on the parameters \\(\\gamma\\) and \\(h\\) in order that there is a non trivial biologically relevant fixed point?\nRequiring \\[\nN^* &gt;0\n\\]\nimplies \\[\n\\frac{\\gamma}{1+h}-1&gt;0.\n\\]\n\n\n1.6.3 Linear stability\nThe linear stability is determined by \\[\nH'(N_t)=\\frac{\\gamma }{1+{N_t}^2} - \\frac{2\\gamma N_t^2 }{(1+{N_t}^2)^2} - h.\n\\]\nAt \\(N^*=0\\) we obtain \\[\nH'(0)=\\gamma-h.\n\\]\nHence if \\(\\gamma&gt;1+h\\), \\(N^*=0\\) is unstable. Note that this is the condition that determines whether the non-zero fixed point exists or not.\nAt \\[\nN^*=\\sqrt{\\frac{\\gamma}{1+h}-1},\n\\]\n\\[\nH'\\left(\\sqrt{\\frac{\\gamma}{1+h}-1}\\right)=\\frac{\\gamma }{1+\\frac{\\gamma}{1+h}-1} - \\frac{2\\gamma \\frac{\\gamma}{1+h}-1 }{(1+\\frac{\\gamma}{1+h}-1)^2} - h.\n\\]\nHence linear stability is a function of two parameters \\(\\gamma\\) and \\(h\\).\nWe can show that\n\\[\nH'(N^*) = h^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1,\n\\tag{1.7}\\]\nand hence that when \\(h=0\\) we retrieve the stability condition from the previous model.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nh_vec=np.linspace(0.1,5,100)\ngamma_1=(1+h_vec)**2/h_vec\ngamma_2=1+h_vec\ngamma_3=h_vec\n\nfig, ax = plt.subplots(1)\nax.plot(h_vec, gamma_1)\nax.plot(h_vec, gamma_2)\nax.plot(h_vec, gamma_3)\n\nplt.xlabel('$h$')\nplt.ylabel('$\\gamma$')\nplt.show()\n\n\n\n\n\nFigure 1.9: Stability regions for the harvesting model.\n\n\n\n\n\n\n1.6.4 Stability boundaries in the \\(h\\gamma\\) plane\nThe contour at \\(H'(N^*)=1\\) can be identified by solving \\[\nh^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1 = 1,\n\\] yielding \\[\n\\gamma= 1+h.\n\\]\nThe contour at \\(H'(N^*)=-1\\) can be represented by \\[\nh^2\\frac{2}{\\gamma} + h\\frac{2}{\\gamma}(2-\\gamma) + \\frac{2}{\\gamma}-1 = -1,\n\\]\nSolving for \\(\\gamma\\) yields \\[\n\\gamma=\\frac{(1+h)^2}{h}.\n\\]\nIn Figure Figure 1.9 we plot the contours of the hypersurface \\(H'(N^*)\\) at the critical values of \\(-1\\), \\(0\\) and 1. Note that the points in parameter space used to generate the simulation results in Figure 1.8 are \\((h,\\gamma)=(0.1,5)\\) \\((h,\\gamma)=(1,5)\\) and \\((h,\\gamma)=(3,5)\\). Cobweb diagrams in different regions of parameter space are presented in Figure 1.10. The plot in Figure 1.9 can be used to explain why the model transfers from a stable fixed point, through oscillatory fixed point and back to a stable fixed point as the harvesting rate increases from 0.1, to \\(1\\) and then 5?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=10\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.2\nh_1=0.1\nh_2=1.0\nh_3=3.0\nr=5.0\n\nN_max=4.0\n\ndef rhs(x,par):\n  r=par[0]\n  h=par[1]\n  f=r*x/(1+x**2)-h*x\n  return f\n\n\nN1,CobwebSol1=SolveSingleDiffAndCobweb(t,rhs,N_0,[r,h_1])\nN2,CobwebSol2=SolveSingleDiffAndCobweb(t,rhs,N_0,[r,h_2])\nN3,CobwebSol3=SolveSingleDiffAndCobweb(t,rhs,N_0,[r,h_3])\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,[r,h_1])\nH_N_plot2=rhs(N_plot,[r,h_2])\nH_N_plot3=rhs(N_plot,[r,h_3])\n\nfig, ax = plt.subplots(1,3)\n\nax[0].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0].plot([0, N_max], [0, N_max])\nax[0].plot(N_plot, H_N_plot1)\n\nax[1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[1].plot([0, N_max], [0, N_max])\nax[1].plot(N_plot, H_N_plot2)\n\nax[2].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[2].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[2].plot([0, N_max], [0, N_max])\nax[2].plot(N_plot, H_N_plot3)\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.10: Cobweb diagrams for different values of h.\n\n\n\n\nWe can construct a cobweb diagram for the case \\((h,\\gamma)=(3,5)\\).\nMany of the above calculations can be aided using a symbolic calculator:\n\n\nCode\nimport numpy as np\nimport sympy as sp\n\n\n\n# Define variables and constants\nh=sp.symbols(\"h\",real=True,nonnegative=True)\ngamma=sp.symbols(\"gamma\",real=True,nonnegative=True)\nN = sp.symbols(\"N\",real=True,nonnegative=True)\n\n# Define H\nH=gamma*N/(1+N**2)-h*N\n\n# Solve the FP equation\nfp=sp.solve(H-N,N,dict=True)\n\nprint(\"The FPs are:\")\nprint(fp[0])\nprint(fp[1])\nprint(fp[2])\n\n# Compute H prime\nH_p=H.diff(N)\n\n\nprint(\"The derivative of H is:\")\nprint(sp.simplify(H_p))\n\n\n# Evaluate derivative\n\nprint(\"The derivative evaluated at FP 0 is:\")\nsol1=fp[0][N]\nH_p_eval_0=sp.simplify(H_p.subs(N,sol1))\n\nprint(H_p_eval_0)\n\nprint(\"The derivative evaluated at FP 2 is:\")\nsol2=fp[2][N]\nH_p_eval_2=H_p.subs(N,sol2)\n\nprint(sp.simplify(H_p_eval_2))\n\n\nThe FPs are:\n{N: 0}\n{N: -sqrt(gamma - h - 1)/sqrt(h + 1)}\n{N: sqrt(gamma - h - 1)/sqrt(h + 1)}\nThe derivative of H is:\n-N**2*gamma/(N**2 + 1)**2 + gamma/(N**2 + 1)**2 - h\nThe derivative evaluated at FP 0 is:\ngamma - h\nThe derivative evaluated at FP 2 is:\n(gamma + 2*(h + 1)*(-gamma + h + 1))/gamma"
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#oscillations",
    "href": "MA32009-SinglePopDiscreteTimea.html#oscillations",
    "title": "1  Single species population dynamics",
    "section": "1.7 Oscillations",
    "text": "1.7 Oscillations\nLinear stability analysis describes the evolution of small perturbations close to a fixed point. But far from a fixed point the nonlinear terms that were dropped in a Taylor expansion are no longer negligible. In particular, in the case where \\(H'(N^*)&lt;-1\\), it can be the case that regions of parameter space in which a fixed point is oscillatory unstable can give rise to periodic and chaotic solutions.\n### Defining a periodic solution Consider the general form \\[\nN_{t+1}=H(N_t)\n\\tag{1.8}\\] A solution to Equation 1.8 isdefined to be periodic with period \\(T\\) if\n\\[\n\\begin{aligned}\nN_{t+T}&=N_t \\ \\  \\forall t,\nN_{t+\\tau}&\\neq N_t  \\ \\ \\forall t, \\  \\ \\ \\tau&lt;T.\n\\end{aligned}\n\\]\nPeriod 2 solutions can be identified by looking for solutions that repeat after two iterations. Suppose \\(\\bar{N}\\) is a period 2 solution of Equation 1.8 and let \\(\\bar{N}=N_1\\). Then \\[\nN_{2}=H(\\bar{N}).\n\\] However, \\[\nN_{3}=H(N_2)=H(H(\\bar{N}))\n\\] and if \\(\\bar{N}\\) is a period 2 solution \\(N_3=N_1=\\bar{N}\\). Hence period 2 solutions can be calculated by solving the algebraic equation \\[\n\\bar{N}=H(H(\\bar{N})).\n\\] Note that period two solutions are fixed points of the problem \\[\nN_{t+2}=H^2(N_t)=g(N_t).\n\\] Using the tools we have developed, period solutions and their stability can be determined. Furthermore, longer period solutions can be identified by generalising the argument but at the expense of ever increasingly complicated right-hand side functions. In many systems, such as the harvesting model and the logistic equation, increasing the growth rate parameter leads initially to the fixed point becoming unstable and the emergence of period two solutions, then period 4 solutions and so on until eventually there is a transition to chaotic solutions (see, for example, Figure 1.11).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=40\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\nN_2 = np.zeros_like(t,dtype=float)\n\nN_0=0.1\nr_1=9.68\nr_2=12.221\nr_3=30.25\nh=0.1\n\nN_max=20.0\n\ndef rhs(x,par):\n  r=par[0]\n  h=par[1]\n  f=r*x/(1+x**2)-h*x\n  return f\n\n\n\nN1,CobwebSol1=SolveSingleDiffAndCobweb(t,rhs,N_0,[r_1,h])\nN2,CobwebSol2=SolveSingleDiffAndCobweb(t,rhs,N_0,[r_2,h])\nN3,CobwebSol3=SolveSingleDiffAndCobweb(t,rhs,N_0,[r_3,h])\n\nN_plot=np.linspace(0,N_max,100)\nH_N_plot1=rhs(N_plot,[r_1,h])\nH_N_plot2=rhs(N_plot,[r_2,h])\nH_N_plot3=rhs(N_plot,[r_3,h])\n\nfig, ax = plt.subplots(3,2)\n\nax[0,0].plot(t, N1)\n\nax[0,1].plot(CobwebSol1[:,0], CobwebSol1[:,1])\nax[0,1].plot(CobwebSol1[0,0], CobwebSol1[0,1],'*')\nax[0,1].plot([0, N_max], [0, N_max])\nax[0,1].plot(N_plot, H_N_plot1)\n\nax[1,0].plot(t, N2)\n\nax[1,1].plot(CobwebSol2[:,0], CobwebSol2[:,1])\nax[1,1].plot(CobwebSol2[0,0], CobwebSol2[0,1],'*')\nax[1,1].plot([0, N_max], [0, N_max])\nax[1,1].plot(N_plot, H_N_plot2)\n\nax[2,0].plot(t, N3)\n\nax[2,1].plot(CobwebSol3[:,0], CobwebSol3[:,1])\nax[2,1].plot(CobwebSol3[0,0], CobwebSol3[0,1],'*')\nax[2,1].plot([0, N_max], [0, N_max])\nax[2,1].plot(N_plot, H_N_plot3)\n\nplt.xlabel('$N_t$')\nplt.ylabel('$N_{t+1}$')\nplt.show()\n\n\n\n\n\nFigure 1.11: Transition form period 2 to period 4 solutions in the harvesting model\n\n\n\n\nExercise: identify an equation satisfied by period 2 solutions of the logistic map \\[\nN_{t+1}=rN_1(1-N_t).\n\\]"
  },
  {
    "objectID": "MA32009-SinglePopDiscreteTimea.html#a-note-on-the-modelling-of-real-world-fish-stocks",
    "href": "MA32009-SinglePopDiscreteTimea.html#a-note-on-the-modelling-of-real-world-fish-stocks",
    "title": "1  Single species population dynamics",
    "section": "1.8 A note on the modelling of real-world fish stocks",
    "text": "1.8 A note on the modelling of real-world fish stocks\nYou can find reports on fish stocks (measurements and modelling work) from the International Council for the Exploration of the Sea at the link. Here’s a link to the data for Atlantic salmon. Note that although the models we have worked on are not detailed enough to accurately model real fish population dynamics, many of the principles we have covered arise in the cutting edge models."
  },
  {
    "objectID": "DiscreteModels2d.html",
    "href": "DiscreteModels2d.html",
    "title": "2  Multi species population dynamics",
    "section": "",
    "text": "3 Multiple species in discrete time\nIn this chapter we generalise the previous approach by considering the population dynamics of two interacting populations."
  },
  {
    "objectID": "DiscreteModels2d.html#a-general-model-of-two-interacting-species-in-discrete-time",
    "href": "DiscreteModels2d.html#a-general-model-of-two-interacting-species-in-discrete-time",
    "title": "2  Multi species population dynamics",
    "section": "3.1 A general model of two interacting species in discrete time",
    "text": "3.1 A general model of two interacting species in discrete time\nLet \\(N_t\\) and \\(P_t\\) represent population densities at time \\(t\\) where \\(t\\) is a discrete variable.\nWe consider governing equations of the form \\[\n\\begin{aligned}\nN_{t+1}=f(N_t,P_t), \\nonumber \\\\\nP_{t+1}=g(N_t,P_t).\n\\end{aligned}\n\\tag{3.1}\\] where the population dynamics of the species are coupled to one another via the functions \\(f\\) and \\(g\\).\nThe precise form for \\(f\\) and \\(g\\) will be defined by the biological system under study. Typical interpopulation interactions that are studied are: predator prey models, competition and cooperation."
  },
  {
    "objectID": "DiscreteModels2d.html#general-techniques-for-analysing-coupled-first-order-difference-equations",
    "href": "DiscreteModels2d.html#general-techniques-for-analysing-coupled-first-order-difference-equations",
    "title": "2  Multi species population dynamics",
    "section": "3.2 General techniques for analysing coupled first order difference equations",
    "text": "3.2 General techniques for analysing coupled first order difference equations\n\n3.2.1 Fixed points\nThe fixed points of Equation 3.3 \\((N^*,P^*)\\) satisfy \\[\n\\begin{aligned}\nN^*=g(N^*,P^*) \\nonumber \\\\\nP^*=f(N^*,P^*).\n\\end{aligned}\n\\]\n\n\n\n3.2.2 Linear stability analysis\nTo consider linear stability of a steady state we consider the change of variable \\[\n\\begin{aligned}\nN_t&=N^*+\\hat{N}_{t},   \\nonumber\\\\\nP_t&=P^*+\\hat{P}_{t}.  \\nonumber\n\\end{aligned}\n\\] After substitution in Equation 3.3 and making Taylor expansions about \\((N^*,P^*)\\) we obtain at leading order\n\\[\n\\left(\\begin{array}{c}\n\\hat{N}_{t+1} \\\\ \\hat{P}_{t+1}\\end{array}\\right) = \\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial N}&\\frac{\\partial f}{\\partial P} \\\\ \\frac{\\partial g}{\\partial N }&\\frac{\\partial g}{\\partial P} \\end{array}\\right)_{(N^*,P^*)} \\left(\\begin{array}{c} \\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right).\n\\tag{3.2}\\]\nNote the appearance of the Jacobian matrix \\[\nA= \\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial N}&\\frac{\\partial f}{\\partial P} \\\\ \\frac{\\partial g}{\\partial N }&\\frac{\\partial g}{\\partial P} \\end{array}\\right)_{(N^*,P^*)} \\left(\\begin{array}{c} \\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right).\n\\]\n\n\n3.2.3 Solving the linearised problem\nDefining \\[\n\\mathbf{w}_t=\\left(\\begin{array}{c}\\hat{N}_{t} \\\\ \\hat{P}_{t}\\end{array}\\right),\n\\]\n\\[\n\\mathbf{w}_{t+1}=A\\mathbf{w}_{t}\n\\] By solving this linear system we can investigate whether small perturbation about the fixed point grow or decay in magnitude as time evolves and hence determine the linear stability of the fixed point.\nThe solution of Equation 3.2 takes the form \\[\n\\mathbf{w}_t=\\sum_{i=1}^2 C_i \\lambda_i^t\\mathbf{c}_i,\n\\] where the \\(C_i\\)’s are constants determined by initial conditions and the \\(\\lambda_i\\)’s and \\(\\mathbf{c}_i\\)’s are the eigenvalues and eigenvectors of A, respectively. From this form we can see that if the magnitude of all eigenvalues is less than one, i.e. \\[\n|\\lambda_i|&lt;1, \\ \\ \\ \\ \\ \\forall i,\n\\] the fixed point is linearly stable. If at least one of the eigenvalues has \\(|\\lambda_i|&gt;1\\) then the fixed point is unstable to linear perturbations.\n\n\n\n3.2.4 Jury conditions\nIn many cases it is not very useful to explicitly compute the eigenvalues of the Jacobian matrix. In such cases we can employ the Jury conditions in order to determine when a fixed point is linearly stable.\nRecall that for a two dimensional matrix, the eigenvalues satisfy the quadratic characteristic equation\n\\[\n\\lambda^2- trA \\lambda + detA=0.\n\\]\nThe stability of the fixed is guaranteed if \\(|\\lambda _i|&lt;1\\) \\(\\forall i\\).\nConsider the characteristic equation \\[\nP(\\lambda)=\\lambda^2 + a \\lambda +b=0,\n\\] where \\(a,b \\in \\Re\\). Note that \\(a=-tr{A}\\) and \\(b=\\det{A}\\).\nThe Jury conditions state that \\(|\\lambda_i |&lt;1 \\forall \\ \\  i\\) if, and only if, * \\(b&lt;1\\), * \\(1+a+b&gt;0\\), * *\\(1-a+b&gt;0\\). See Figure 3.1 for schematic diagram.\n\n\n\nFigure 3.1: Jury conditions\n\n\n\n\n3.2.5 Proof of the Jury conditions\nThe roots of \\(P(\\lambda)\\) are \\[\n\\lambda_{1,2}=\\frac{-a \\pm \\sqrt{a^2-4b}}{2}.\n\\]\n\n\n3.2.6 Complex roots\nSuppose \\(a^2-4b&lt; 0\\). The roots are complex. Since \\(b\\) is equal to the product of the roots, we find that\n\\[\nb=\\lambda_1\\lambda_2 = |\\lambda_1|^2 = |\\lambda_2^2|.\n\\] Hence \\(\\lambda_i&lt;1\\) \\(\\forall \\ \\ i\\) if and only if \\(b&lt;1\\).\nFor the other conditions we introduce the identity: \\[\na^2-4b=(|a|-2)^2 - 4(1+b-|a|).\n\\] Therefore, when \\(a^2-4b&lt;0\\), the inequality requires \\[\n(|a|-2)^2 - 4(1+b-|a|)&lt;0.\n\\] This can only occur if \\[\n1+b-|a| &gt;0 \\implies 1+b-a&gt;0 \\ \\ \\textrm{and} \\ \\  1+b+a&gt;0.\n\\]\n\n\n3.2.7 Real roots\nSuppose \\(a^2-4b\\geq 0\\)\nThe largest magnitude of the roots is \\[\nR=\\max\\{|\\lambda_1|,|\\lambda_2|\\} =  \\frac{|a| + \\sqrt{a^2-4b}}{2}.\n\\] This is an increasing function of \\(|a|\\).\n\\(R=1\\) \\[\n\\implies  \\frac{|a| + \\sqrt{a^2-4b}}{2}=1\n\\implies |a|-2=-\\sqrt{|a|^2-4b}\n\\implies |a|^2-4|a|+4=|a|^2-4b\n\\implies |a|=b+1.\n\\] Hence \\(0\\leq R &lt; 1\\) if and only if \\(0\\leq |a|&lt;1+b\\). Also, since \\(|\\lambda_i|&lt;1 \\forall i\\) implies that \\(|\\lambda_1\\lambda_2|&lt;1\\), it follows that \\(|b|&lt;1\\) must hold."
  },
  {
    "objectID": "DiscreteModels2d.html#host-parasitoid-infection",
    "href": "DiscreteModels2d.html#host-parasitoid-infection",
    "title": "2  Multi species population dynamics",
    "section": "3.3 Host Parasitoid infection",
    "text": "3.3 Host Parasitoid infection\nParasitoids are creatures that have a free living and parasitic stage. The free-living adult lays eggs in a host that later hatch and develop after eating the host. The discrete stages of the parasitoids life cycle and the dependence on its reproduction on the availability of host suggest a discrete time, multi species models. Let \\(N_{t}\\) and \\(P_t\\) represent the number of hosts and parasitoids at time \\(t\\), respectively. Let \\(R_0\\) represent the reproductive ratio of host in the absence of parasites and \\(C\\) the average number of viable eggs laid by each parasite on a host. ### Model equations\nWe consider equations of the form \\[\n\\begin{aligned}\nN_{t+1}&=R_0N_t f(N_t,P_t), \\nonumber \\\\\nP_{t+1}&=CN_t (1- f(N_t,P_t)). \\nonumber\n\\end{aligned}\n\\tag{3.3}\\]\nThe justification for this form is that at a given time \\(t\\) there are \\(N_t\\) hosts. A total of \\(N_t f(N_t,P_t)\\) escape the parasite and are able to reproduce whilst a total of \\(N_t(1-f(N_t,P_t))\\) do not escape the parasite and lead to parasitic reproduction at the next time step.\nChoosing \\[\nf(N_t,P_t)=e^{-aP_t},\n\\] yields the Nicholson Bailey model \\[\n\\begin{aligned}\nN_{t+1}=R_0N_t e^{-aP_t}, \\nonumber \\\\\nP_{t+1}=CN_t (1- e^{-aP_t}).\n\\end{aligned}\n\\tag{3.4}\\]\n\n\n3.3.1 Numerical solution\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nT=100\n\nt = np.arange(0, T, 1)\nN = np.zeros_like(t,dtype=float)\n\n\ndef rhs(x,par):\n  N=x[0]\n  P=x[1]\n\n  R_0=par[0]\n  C=par[1]\n  a=par[2]\n  g=np.zeros_like(x,dtype=float)\n  r=par\n\n  f=np.exp(-a*P)\n\n  g[0]=R_0*N*f\n  g[1]=C*N*(1-f)\n \n  return g\n\ndef SolveSingleDiff(t,rhs,N_0,par):\n  N = np.zeros_like(t,dtype=float)\n  P=  np.zeros_like(t,dtype=float) \n  N[0]=N_0[0]\n  P[0]=N_0[1]\n\n  for i in t:\n    if i&gt;0:\n\n      rhs_eval=rhs([N[i-1],P[i-1]],par)\n      N[i]=rhs_eval[0]\n      P[i]=rhs_eval[1] \n\n  return N,P\n\nR_0=1.5\nC=3.7\na=1.7\n\nN_0=[1.5, 0.1]\nN,P=SolveSingleDiff(t,rhs,N_0,[R_0,C,a])\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(t, N)\nplt.xlabel('$t$')\nplt.ylabel('$N_t$')\nax[1].plot(t, P)\nplt.xlabel('$t$')\nplt.ylabel('$P_t$')\nplt.show()\n\n\n\n\n\nFigure 3.2: A plot of the Nicholson Bailey model solution.\n\n\n\n\n\n\n3.3.2 Fixed points\nThe fixed points satisfy \\[\n\\begin{aligned}\nN^*=R_0N^*e^{-aP^*}, \\nonumber \\\\\nP^*=CN^* (1- e^{-aP^*}).\n\\end{aligned}\n\\]\nThe first equation yields \\[\nN^*=0.\n\\]\nSuppose \\(N^*\\neq 0\\) \\[\n1=R_0e^{-aP^*}.\n\\]\nHence \\[\nP^*=\\frac{1}{a}\\ln R_0.\n\\]\nConsider the second equation. Suppose \\(N^*=0\\). We obtain \\[\nP^*=0.\n\\] Hence one fixed point is \\((0,0)\\).\nSuppose \\(P^*=\\frac{1}{a}\\ln R_0\\). \\[\n\\frac{1}{a}\\ln R_0 = CN^*(1-\\frac{1}{R_0}).\n\\] Hence \\[\nN^* = \\frac{\\frac{1}{a}\\ln R_0 }{C(1-\\frac{1}{R_0})} = \\frac{R_0\\ln R_0 }{aC(R_0-1)}.\n\\] Hence the second fixed point is \\[\n\\left(\\frac{R_0\\ln R_0 }{aC(R_0-1)},\\frac{1}{a} \\ln R_0 \\right).\n\\]\nWe can verify by substitution that \\[\n\\left(\\frac{R_0\\ln R_0 }{aC(R_0-1)},\\frac{1}{a} \\ln R_0 \\right).\n\\] is a fixed point. We can then deduce a condition on the model parameters that must hold in order that the fixed point is biologically relevant.\nTo verify by substitution we substitute the proposed solution into the governing equations. Note that \\[\ne^{-aP^*}=\\frac{1}{R_0}.\n\\] In this case \\[\n\\begin{aligned}\n\\frac{R_0\\ln R_0 }{aC(R_0-1)}=R_0 \\frac{R_0\\ln R_0 }{aC(R_0-1)}\\frac{1}{R_0}, \\nonumber \\\\\n\\frac{1}{a} \\ln R_0=C\\frac{R_0\\ln R_0 }{aC(R_0-1)} (1-\\frac{1}{R_0}).\n\\end{aligned}\n\\tag{3.5}\\]\nCancellation shows that both equations hold. Hence the fixed point is a valid fixed point. To be biologically relevant we require that both components of the solution are real and positive. In this case this leads to the condition \\(R_0&gt;1\\)}.\n\n\n3.3.3 Linear stability\nThe Jacobian matrix is given by \\[\nA_{(N_t,P_t)}= \\left(\\begin{array}{cc}\nR_0e^{-aP_t}&-R_0aN_te^{-aP_t} \\\\ c(1-e^{-aP_t})&aCN_te^{-aP_t} \\end{array}\\right).\n\\]\n\n\n3.3.4 Linear stability of the trivial fixed point\nEvaluating at (0,0) yields \\[\nA= \\left(\\begin{array}{cc}\nR_0 & 0 \\\\ 0 & 0 \\end{array}\\right).\n\\] Hence the eigenvalues are \\(R_0\\) and 0. If \\(0&lt;R_0&lt;1\\) (0,0) is stable whilst if \\(R_0&gt;1\\) (0,0) is unstable.\n\n\n3.3.5 Linear stability of the nontrivial fixed point\nWe can show that the Jacobian matrix evaluated at the nontrivial fixed point can be written as \\[\nA= \\left(\\begin{array}{cc}\n1&-\\frac{R_0 \\ln R_0}{c(R_0-1)} \\\\ c(1-\\frac{1}{R_0})&\\frac{\\ln R_0}{R_0-1} \\end{array}\\right) .\n\\] and deduce that the eigenvalues of A satisfy the characteristic polynomial \\[\n\\lambda^2 - \\lambda\\left(1+\\frac{\\ln R_0}{R_0-1}\\right)+ \\frac{R_0\\ln(R_0)}{R_0-1}=0.\n\\]\n\n\n\n\n3.3.6 Employing the Jury conditions\nTo proceed with linear stability analysis we employ the Jury conditions. Consider the polynomial \\[\n\\lambda^2+a\\lambda+b=0,\n\\] In our case \\[\na= - (1+\\frac{\\ln R_0}{R_0-1})\n\\] and \\[\nb=\\frac{R_0\\ln(R_0)}{R_0-1}.\n\\]\nThe third Jury condition (\\(b&lt;1\\)) implies that for linear stability \\[\n\\ln R_0 &lt; 1-\\frac{1}{R_0}.\n\\] To demonstrate that this inequality is not true for \\(R_0&gt;1\\), let \\(f_1=\\ln R_0\\) and \\(f_2=1- 1/R_0\\). When \\(R_0=1\\), \\(f_1=f_2=0\\). However, \\[\nf_1'=\\frac{1}{R_0}  \\ \\ \\textrm{and} \\ \\ f_2'=\\frac{1}{R_0^2},\n\\] implies \\[\nf_1'&gt;f_2'  \\ \\ \\forall \\ R_0&gt;1.\n\\] Hence \\[\n\\ln R_0 &gt; 1-\\frac{1}{R_0}.\n\\] Hence the fixed point is unstable if \\(R_0&gt;1\\).\n\n\n3.3.7 Symbolic calculations in Python\nBelow sympy is used to identify the fixed points. The Jacobian matrix is then computed and evaluated at the fixed points.\n\n\nCode\nimport numpy as np\nimport sympy as sp\n\n\n# Define variables and constants\nR_0=sp.symbols(\"R_0\",real=True,nonnegative=True)\na=sp.symbols(\"a\",real=True,nonnegative=True)\nC=sp.symbols(\"C\",real=True,nonnegative=True)\n\nN = sp.symbols(\"N\",real=True,nonnegative=True)\nP = sp.symbols(\"P\",real=True,nonnegative=True)\n\n# Define H\nH_1=R_0*N*sp.exp(-a*P)\nH_2=C*N*(1-sp.exp(-a*P))\n\n# Solve the FP equation\nfp=sp.solve([H_1-N,H_2-P],[N,P],dict=True)\n\nprint(\"The FPs are:\")\nprint(fp[0])\nprint(fp[1])\n\n# Compute the Jacobian\nA=sp.Array( [[H_1.diff(N), H_1.diff(P)],[H_2.diff(N), H_2.diff(P)]])\n\nprint(\"The Jacobian of H is:\")\nprint(sp.simplify(A))\n\n\n# Evaluate derivative\n\nprint(\"The Jacobian evaluated at FP 0 is:\")\nsol0_N=fp[0][N]\nsol0_P=fp[0][P]\n\nA_eval_0=A.subs([(N,sol0_N),(P,sol0_P)])\nprint(A_eval_0)\n\nprint(\"The Jacobian evaluated at FP 1 is:\")\nsol1_N=fp[1][N]\nsol1_P=fp[1][P]\n\nA_eval_1=A.subs([(N,sol1_N),(P,sol1_P)])\nprint(A_eval_1)\n\n\nThe FPs are:\n{N: 0, P: 0}\n{N: R_0*log(R_0)/(C*a*(R_0 - 1)), P: log(R_0)/a}\nThe Jacobian of H is:\n[[R_0*exp(-P*a), -N*R_0*a*exp(-P*a)], [C - C*exp(-P*a), C*N*a*exp(-P*a)]]\nThe Jacobian evaluated at FP 0 is:\n[[R_0, 0], [0, 0]]\nThe Jacobian evaluated at FP 1 is:\n[[1, -R_0*log(R_0)/(C*(R_0 - 1))], [C*(1 - 1/R_0), log(R_0)/(R_0 - 1)]]"
  },
  {
    "objectID": "SinglePopODEMOdels.html#the-malthusian-linear-model",
    "href": "SinglePopODEMOdels.html#the-malthusian-linear-model",
    "title": "3  Single species population dynamics",
    "section": "3.1 The Malthusian (linear) model",
    "text": "3.1 The Malthusian (linear) model\n\n3.1.1 Deriviation\nAs time is now a continuous variable, we consider an interval of time \\(\\delta t\\). Consider a population of size \\(N(t)\\). If the per capita production rate is \\(b\\), then in time \\(\\delta t\\) the increase in population size will be \\[\nb N(t) \\delta t.\n\\] Similarly, if the per capita death rate is \\(d\\), the decrease in population size in time \\(\\delta t\\) will be \\[\nd N(t) \\delta t.\n\\] Hence \\[\nN(t+\\delta t)= N(t) + (bN(t)-dN(t))\\delta t.\n\\] Rearranging and taking the limit as \\(\\delta t \\rightarrow 0\\) yields \\[\n\\frac{dN}{dt}=(b-d)N=rN(t).\n\\]\n\n\n3.1.2 Solution\nThe solution is given by \\[\nN(t)=N_0\\exp(rt).\n\\]\nWe can describe qualitatively different solutions behaviours.\nIf \\(r&gt;0\\) the solution increases exponentially with time. If \\(r&lt;0\\) it decreases exponentially. When \\(r=0\\) the solution is constant.\nMalthusian growth in the continuous time model leads to either a constant population, exponentially increasing or exponentially decreasing growth. As was the case for the discrete time model, such a model could account for biological system only in particularly limited circumstances.\nThe Malthusian model (constant per capita growth rate) can exhibit a limited range of behaviour. To account for limitation of population growth at large population densities due to, for example, limited resources, we consider nonlinear per capita growth rates."
  },
  {
    "objectID": "SinglePopODEMOdels.html#tools-for-analysing-the-dynamics-of-a-single-population-in-continuous-time",
    "href": "SinglePopODEMOdels.html#tools-for-analysing-the-dynamics-of-a-single-population-in-continuous-time",
    "title": "3  Single species population dynamics",
    "section": "3.2 Tools for analysing the dynamics of a single population in continuous time",
    "text": "3.2 Tools for analysing the dynamics of a single population in continuous time\nLet \\(N=N(t)\\). We consider the general form for a single species model defined in continuous time \\[\n\\frac{dN}{dt}=f(N)N=H(N),\n\\tag{3.1}\\] where \\(f\\) is the per capita growth rate and \\(H\\) is the net growth rate.\n\n3.2.1 Numerical solution\nAlthough an equation of the form Equation 3.1 may not be explicitly integrable, so long as the right-hand side is sufficiently well behaved, we can numerically integrate the problem (e.g. using packages such as Python’s odeint). Such a technique provides a numerical approximation to the exact solution, given specific values of model parameters and initial conditions (i.e. we can graph solutions).\n\n\n3.2.2 Nondimensionalisation\nWe nondimensionalise a model by changing from variables that have dimensions (both dependent and independent) to variables that are dimensionless.\n\n3.2.2.1 Dimensional analysis\nThe dimensions/units of each term in a model must be consistent. This observation helps to determine the units of different parameters in a model.\nFor example, we can deduce that the units of the parameter \\(r\\) in the Malthusian model \\[\n\\frac{dN}{dt}=rN.\n\\]\nThe units of the left-hand term are \\[\n\\frac{\\# pop density}{\\# time}.\n\\]\nThe units of the term on the right-hand side are \\[\n\\#r\\#popdensity.\n\\]\nFor dimensional consistency \\[\n\\#r = \\frac{1}{\\#time}.\n\\]\n\n\n3.2.2.2 Dimensionless variables\nWe could nondimensionalise Equation 3.1 by defining the dimensionless variables \\[\n\\begin{aligned}\nn=\\frac{N}{\\tilde{N}} \\nonumber \\\\\n\\tau=\\frac{t}{\\tilde{T}}.\\nonumber\n\\end{aligned}\n\\]\nMaking the proposed change of variables in Equation 3.1 we obtain the dimensionless model \\[\n\\frac{dn}{d\\tau}= \\frac{\\tilde{T}}{\\tilde{N}}H(\\tilde{N}n(\\tau)).\n\\] The choice for scalings is in general not unique (i.e. \\(N^*\\) and \\(T^*\\)). Appropriate choices can result in fewer dimensionless parameters in the dimensionless model.\nExercise: Show that the Mathusian model \\[\n\\frac{dN}{dt}=rN\n\\] can be written in nondimensional form \\[\n\\frac{dn}{d\\tau}=n.\n\\]\nIntroducing dimensionless variable \\[\nn=\\frac{N}{\\tilde{N}} \\quad \\tau=\\frac{t}{\\tilde{T}}\n\\] yields \\[\n\\frac{dn}{d\\tau}=r\\tilde{T}n\n\\] Choosing \\[\n\\tilde{T}=\\frac{1}{r}\n\\] yields \\[\n\\frac{dn}{d\\tau}=n.\n\\]\n\n\n\n3.2.3 Steady-state\nWe denote steady-state solutions of Equation 3.1 using \\(N=N^*\\). At a steady-state, \\[\n\\frac{dN}{dt}=0\n\\] and hence steady-states can be obtained by solving the algebraic equation \\[\nH(N^*)=0.\n\\]\n\n\n\n3.2.4 Linear stability analysis\n\n3.2.4.1 A change of dependent variable\nTo perform a linear stability analysis we make the change of variables \\[\nN(t)=N^*+\\hat{N}(t)\n\\] where the new dependent variable, \\(\\hat{N}(t)\\), is a perturbation about the steady state.\nThe time derivative on the left-hand side of Equation 3.1 transforms to \\[\n\\frac{dN}{dt}= \\frac{d }{dt} (N^*) + \\frac{d }{dt}(\\hat{N}(t))=\\frac{d\\hat{N}(t) }{dt}.\n\\] Hence Equation 3.1 transforms to \\[\n\\frac{d\\hat{N}(t) }{dt} = H(N^*+\\hat{N}(t)).\n\\]\n\n\n3.2.4.2 Taylor expansion and a linear system\nEmploying the Taylor expansion on the right-hand side of Equation 3.1 and making the assumption that perturbations are small \\[\n\\frac{d\\hat{N}(t) }{dt} = H(N^*)+  H'(N^*)\\hat{N}(t) + H''(N^*)\\hat{N}^2(t) + h.o.t.\n\\] Noting that\n\\[\nH(N^*)=0\n\\] and retaining linear terms yields \\[\n\\frac{d\\hat{N}(t) }{dt} =  H'(N^*)\\hat{N}(t)\n\\] with solution \\[\n\\hat{N}(t)=  \\eta e^{H'(N^*) t}\n\\] where \\(\\eta\\) is some initial perturbation about the steady-state.\n\n\n3.2.4.3 A condition for linear stability\nWhen \\(H'(N^*)&gt;0\\) the perturbation grows exponentially fast and the steady-state is unstable. When \\(H'(N^*)&lt;0\\) the perturbation decays exponentially fast and the steady-state is stable.\n\n\n\n\n\n3.2.5 Graphical solution\nWe can graphically identify steady-states and their stability by plotting \\(dN/dt\\) against \\(N(t)\\). Steady-states arise at the roots of \\(H(N)\\). The sign of the derivative at a root determines its linear stability.\n\n\n3.2.6 Bifurcation diagrams\nBifurcations arise when the number of solutions or their stability changes at a given value of a model parameter. By plotting the steady state solutions against a model parameter and using annotation to represent stability of solutions we can obtain a bifurcation diagram.\nAs an exercise perform a qualitative analysis of the Malthusian model."
  },
  {
    "objectID": "SinglePopODEMOdels.html#the-logistic-growth-model",
    "href": "SinglePopODEMOdels.html#the-logistic-growth-model",
    "title": "3  Single species population dynamics",
    "section": "3.3 The logistic growth model",
    "text": "3.3 The logistic growth model\n\n3.3.1 Model development\nLet \\(N=N(t)\\). The logistic model, due to Verhulst, takes the form \\[\n\\frac{dN}{dt}=rN(t)\\left (1-\\frac{N(t)}{K}\\right),\n\\tag{3.2}\\]\nwhere \\(r\\) is the linear growth rate and \\(K\\) is carrying capacity. We consider both \\(r,K\\in \\Re^+\\).\nQuestions to ask of such a model are: what type of biologically realistic solutions does it possess? Are there steady-states? If so, are they stable or unstable? Are there bifurcations in solutions?\n\n3.3.1.1 Numerical solutions\nIn Figure 3.1 we present numerical solutions of equation using different initial conditions. Note the limiting behaviour of solutions as \\(t\\rightarrow \\infty\\). In Figure 3.1 it is clear that even though some solutions are initialised at \\(N_0=0.1\\), much closer to \\(N^*=0\\) than \\(N^*=K\\), they tend to the limit \\(N=K\\). Why do solutions not tend to \\(N^*=0\\)?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\nN_max=1.1\nN_0=0.1\nK=12\nr_1=0.22\nr_2=0.42\nr_3=0.72\n\nT=20\nn_0=1.5\nn_vec=np.linspace(0,N_max,100)\n\ndef rhslogistic_model(x,t,r,K):\n\n  rhs=r*x*(1-x/K)\n  return rhs\n\nt=np.linspace(0,T,100)\n\nsol1=odeint(rhslogistic_model,n_0,t,args=(r_1,K))\nsol2=odeint(rhslogistic_model,n_0,t,args=(r_2,K))\nsol3=odeint(rhslogistic_model,n_0,t,args=(r_3,K))\n\nfig, ax = plt.subplots(1)\n\nax.plot(t, sol1,t, sol2,t, sol3)\nplt.xlabel('$t$')\nplt.ylabel('$N$')\nplt.grid(True)\nplt.legend(['r='+str(r_1),'r='+str(r_2),'r='+str(r_3)])\nplt.show()\n\n\n\n\n\nFigure 3.1: RHS of spr. budworm model\n\n\n\n\n\n\n3.3.1.2 Dimensional analysis and nondimensionalisation\n\\(N\\) represents the population density and has units of one over area (say \\(1/m^2\\)) and \\(t\\) has units of time (say, seconds, \\(s\\)). Hence the left-hand side of Equation 3.2 has units of \\(1/(m^2 s)\\). The first term on the right-hand side of Equation 3.2 is \\(rN\\). \\(N\\) has units \\(1/m^2\\) hence the parameter \\(r\\) must have units of \\(1/s\\) for dimensional consistency. This is consistent as \\(r\\) represents the linear growth rate.\nThe second term has the form \\(rN^2/K\\). Given the chosen units for \\(r\\) and \\(N\\), the parameter \\(K\\) must have dimensions \\(1/m^2\\). Again, this is consistent as \\(K\\) is a carrying capacity (i.e. it has units of population density).\nWe define the nondimensionalised variables \\[\nn=\\frac{N}{\\tilde{N}} \\ \\ \\ \\ \\ \\ \\tau=\\frac{t}{\\tilde{T}}\n\\] where \\(\\tilde{N}\\) and \\(\\tilde{T}\\) are constants that have units of population density and time, respectively. Hence Equation 3.2 transforms, upon change of variables, to \\[\n\\begin{aligned}\n\\frac{\\tilde{N}}{\\tilde{T} }\\frac{dn}{d\\tau}=r\\tilde{N}n(1-\\frac{n\\tilde{N}}{K}).\n\\end{aligned}\n\\]\nIn the case of the logistic equation there is only one time scale and density scale in the problem, hence we choose \\[\n\\tilde{T}=\\frac{1}{r}  \\ \\ \\ and \\ \\ \\ \\tilde{N}=K\n\\] and the dimensionless model is \\[\n\\begin{aligned}\n\\frac{dn}{d\\tau}= n(1-n)\n\\end{aligned}\n\\tag{3.3}\\] Note that we can retrieve the original equation by rescaling and calculating \\(N=\\tilde{N}n\\) and \\(t=\\tilde{T}\\tau\\).\n\n\n\n3.3.2 Steady states and linear stability\nSteady states satisfy \\[\nn^*(1-n^*)=0.\n\\] Hence \\[\nn^*=0, \\ \\ \\ \\ n^*=1.\n\\]\nTo determine linear stability we compute \\[\nH'(n)= (1-2n).\n\\] When \\(n=n^*=0\\) we obtain \\[\nH'(n)= 1.\n\\] Hence the origin is an unstable steady-state.\nAt the steady-state \\(n^*=1\\) \\[\nH'(n^*)= -1\n\\] hence \\(n^*=1\\) is linearly stable.\nNote that the linear stability analysis can explain the observations regarding the numeric solutions presented in Figure 3.1.\n\n\n3.3.3 Graphical analysis\nIn Figure 3.2 we plot the right-hand side of Equation 3.3. We can qualitatively describe model solutions by considering the arrow along the x axis. Suppose we consider an initial condition with \\(0&lt;n_0&lt;1\\). Using the graph of \\(H(n)\\), \\(dn/d\\tau\\) is positive, hence \\(n\\) increases as a function of time until \\(n(\\tau)\\rightarrow 1\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nN_max=2.1\nK=2\nr=0.2\nN_vec=np.linspace(0,N_max,100)\n\nrhs=r*N_vec*(1-N_vec/K)\nfig, ax = plt.subplots(1)\n\nax.plot(N_vec, rhs)\nplt.xlabel('$N$')\nplt.ylabel('$H(N)$')\nplt.show()\n\n\n\n\n\nFigure 3.2: Right-hand side of the logistic ODE\n\n\n\n\n\n\n3.3.4 An exact solution\nSeparation of variables yields \\[\n\\int\\frac{ dN}{N(1-\\frac{N}{K})}=r\\int dt.\n\\] Using partial fractions \\[\n\\int\\frac{ dN}{N} + \\frac{1}{K}\\int\\frac{ dN}{1-\\frac{N}{K}}=r\\int dt.\n\\] Integration yields \\[\n\\ln N - \\ln\\left(1-\\frac{N}{K}\\right)= \\ln \\frac{N }{1-\\frac{N}{K}} =  rt+C.\n\\] Hence \\[\nN=\\frac{De^{rt}}{1+\\frac{D}{K}e^{rt}}\n\\] Given an initial condition \\(N(0)=N_0\\), we obtain \\[\nN(t)=\\frac{N_0K e^{rt}}{K+N_0(e^{rt}-1)}\n\\]\n\n3.3.4.1 Qualitative analysis of the exact solution\nAs \\(t\\rightarrow \\infty\\), \\(N\\rightarrow K\\). At \\(t=0\\), \\(N=N_0\\) and that for small \\(N_0\\ll K\\) the initial growth phase is exponential, i.e.  \\[\nN(t)\\sim N_0 e^{rt} \\\\ \\ \\ \\ \\ N_0\\ll K, t\\ll \\frac{1}{r}.\n\\]\nNote that in almost all the models that we will consider the above method is not an usually an option as the ODE is not explicitly integrable."
  },
  {
    "objectID": "SinglePopODEMOdels.html#the-spruce-budworm-model",
    "href": "SinglePopODEMOdels.html#the-spruce-budworm-model",
    "title": "3  Single species population dynamics",
    "section": "3.4 The spruce budworm model",
    "text": "3.4 The spruce budworm model\nThe spruce budworm is a destructive and widely distributed forest defoliator in North America. Massive outbreaks occur periodically and can destroy large quantities of valuable spruce and fir. To understand the outbreak behaviour and develop and management strategies, a series of mathematical models have been developed, beginning with Ludwig et al. (1978). The goal of the models is to explain the qualitative pattern of sudden outbreaks and then a sudden collapse.\n\n3.4.1 Model development\nLetting \\(N(t)\\) represent the population size at time \\(t\\), it is assumed that budworm exhibits logistic growth and is subject to predation at rate \\(p(N)\\). A governing ordinary differential equation is given by \\[\n\\frac{dN }{dt}= r_B N\\left(1-\\frac{N}{K_B}\\right)-p(N),\n\\tag{3.4}\\] where \\[\np(N) =\\frac{B N^2}{A^2 +N^2},\n\\] \\(r_B\\) is the linear growth rate, \\(K_B\\) is the carrying capacity, \\(B\\) is the maximum rate of predation and \\(A\\) is a measure of budworm population where predation switches on (specifically, \\(A\\) represents the budworm density at which predation is half its maximum value).\nIt is informative to graph the predation term \\[\np(N) =\\frac{B N^2}{A^2 +N^2},\n\\] and annotate the parameters \\(A\\) and \\(B\\).\nThere is a root at \\(N=0\\). In the limit \\(N\\rightarrow \\infty\\), \\(p \\rightarrow B\\). Note that \\(N=A\\), \\(p=A/2\\). The derivative is \\[\np'(N)=\\frac{2BN}{A^2+N^2} - \\frac{2BN^3}{(A^2+N^2)^2} =  \\frac{2BA^2N}{(A^2+N^2)^2}\n\\] Thus there is a turning point at \\(N=0\\) and \\(p'&gt;0 \\forall N&gt;0\\).\n\n\n3.4.2 Nondimensionalisation\nIntroducing the (as yet unspecified) dimensional scalings \\(\\tilde{N}\\) and \\(\\tilde{T}\\), the model is nondimensionalised as follows\n\\[\nn=\\frac{N}{\\tilde{N}} \\ \\ \\ \\ \\ \\ \\tau=\\frac{t}{\\tilde{T}}.\n\\]\nChanging variables in Equation 3.4 yields\n\\[\n\\frac{\\tilde{N}}{\\tilde{T}}\\frac{d n }{d\\tau}= r_B \\tilde{N}n\\left(1-\\frac{\\tilde{N}n}{K_B}\\right)-\\frac{B\\tilde{N}^2n^2}{A^2+\\tilde{N}^2 n^2}.\n\\]\nAfter some tidying\n\\[\n\\frac{dn }{d\\tau}= r_B\\tilde{T} n\\left(1-\\frac{\\tilde{N}n}{K_B}\\right)-\\frac{B\\tilde{N} \\tilde{T}}{A^2}\\frac{n^2}{1+\\frac{\\tilde{N}^2}{A^2}n^2}.\n\\]\nA natural scale for cell density in the model is given by the parameter \\(A\\), as it determines the density of budworm at which predation is half its maximal value. Hence we choose the scaling on the budworm density \\[\n\\tilde{N}=A.\n\\] Similarly, a natural time scale for the model is given by\n\\[\n\\tilde{T}=A/B.\n\\]\nSubstituting for \\(\\tilde{N}\\) and \\(\\tilde{T}\\) yields \\[\n\\frac{dn }{d\\tau}= rn\\left(1-\\frac{n}{q}\\right)-\\frac{n^2}{1+n^2} = H(n),\n\\tag{3.5}\\] where we define the nondimensional parameters \\[\nr= \\frac{r_B A}{B} \\ \\ \\  \\textrm{and} \\ \\ \\  q=\\frac{K_B}{A}.\n\\]\nNote that Equation 3.5 has two nondimensional parameters and all variables are dimensionless. See Figure 3.3 for a plot of right-hand side of equation Equation 3.5. What kind of behaviours do you expect to see from the model?\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\nN_max=1.1\nN_0=0.1\nq=12\nr_1=0.22\nr_2=0.42\nr_3=0.72\n\nn_vec=np.linspace(0,N_max,100)\n\ndef rhssprucebudworm_model(x,t,r,q):\n\n  rhs=r*x*(1-x/q) - x**2/(1+x**2)\n  return rhs\ndef rhssprucebudworm_model_f(x,t,r,q):\n\n  f=r*x*(1-x/q) \n  return f  \ndef rhssprucebudworm_model_g(x,t,r,q):\n\n  g=x**2/(1+x**2)\n  return g  \n\nrhs1=rhssprucebudworm_model(n_vec,0,r_1,q)\nrhs2=rhssprucebudworm_model(n_vec,0,r_2,q)\nrhs3=rhssprucebudworm_model(n_vec,0,r_3,q)\n\nfig, ax = plt.subplots(1)\n\nax.plot(n_vec, rhs1,n_vec, rhs2,n_vec, rhs3)\nplt.xlabel('$N$')\nplt.ylabel('$H(N)$')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nFigure 3.3: RHS of spr. budworm model\n\n\n\n\n\n\n3.4.3 Numerical solutions\nIn Figure 3.4 we plot some numerical solutions of Equation 3.5 at different values of the parameter \\(r\\).\nNumerical solutions of Equation 3.5 indicate that there is a single stable steady state when \\(r\\) is both small and large but for intermediate values of \\(r\\) there are two stable steady states.\nOur goal is to analyse the model and understand why different parameter values yield these strikingly different model behaviours.\n\n\nCode\nt = np.linspace(0, 100, 101)\nsol1 = odeint(rhssprucebudworm_model, N_0, t, args=(r_1, q))\nsol2 = odeint(rhssprucebudworm_model, N_0, t, args=(r_2, q))\nsol3 = odeint(rhssprucebudworm_model, N_0, t, args=(r_3, q))\n\nplt.plot(t, sol1, 'b', label='r=' +str(r_1))\nplt.plot(t, sol2, 'r', label='r='+str(r_2))\nplt.plot(t, sol3, 'm', label='r='+str(r_3))\n\nplt.legend(loc='best')\nplt.xlabel('t')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 3.4: Numerical solution of spr. budworm model\n\n\n\n\n\n\n3.4.4 Steady state analysis\nLetting \\(n^*\\) represent steady states of Equation 3.5 yields \\[\nrn^*(1-\\frac{n^*}{q})- \\frac{n^*{^2}}{1+n^*{^2}}=0.\n\\] Hence either \\[\nn^*=0,\n\\] or \\(n^*\\) satisfies the cubic equation \\[\nr\\left(1-\\frac{n^*}{q}\\right)- \\frac{n^*}{1+n^*{^2}}=0.\n\\]\nExplicit solutions to such a cubic can be immediately written down but they are cumbersome to work with. We proceed using a graphical/qualitative approach.\nDefine \\[\nf(n^*)=r\\left(1-\\frac{n^*}{q}\\right) \\ \\ \\textrm{and} \\ \\ g(n^*)=\\frac{n^*}{1+n^*{^2}}.\n\\tag{3.6}\\]\nRoots occur for values of \\(n^*\\) that satisfy \\(f=g\\).\nIn Figure 3.5 (a) we fix the parameter \\(q=10\\) and consider model behaviour as a function of the parameter \\(r\\). When \\(r\\gg1\\) there is a nonzero steady-state corresponding to \\(n^*\\gg 1\\). When \\(r\\ll1\\) there is a nonzero steady-state corresponding to \\(n^*\\ll 1\\). In the intermediate case there can be three intersection points.\nWe can use the curve sketching techniques form Tutorial Sheet 1 to sketch \\(f\\) and \\(g\\).\n\\(f\\) is linear. There is a root at \\(n^*=q\\). The derivative is \\(-r/q\\). \\(f(0)\\)=r. \\(g\\) has a unique root at \\(n^*=0\\). The derivative is \\[\ng'=\\frac{1-n{^*}^2}{(1+n^*)^2}.\n\\] There is a turning point at \\(n^*=1\\). Here \\(g=1/2\\). As \\(n^*\\rightarrow \\infty\\), \\(g\\rightarrow 0\\). \\(f'(0)=1\\).\n\n\n3.4.5 Linear stability analysis\nThe linear stability of the model is determined by the quantity \\[\nH'(n)=r(1-\\frac{2n}{q})-\\frac{2{n}}{1+{n}^2} +\\frac{2{n}^3}{(1+{n}^2)^2}.\n\\]\nHence at the steady state \\(n^*=0\\) \\[\nH'(0)=r\n\\] and the steady state is linearly unstable.\nGiven the nonzero steady states have not been calculated explicitly, we proceed using graphical analysis of stability. In Figure 3.5 (b) we plot the right-hand side of Equation 3.5 against \\(n\\) and examine the cases of large, small and intermediate \\(r\\) for a given value of \\(q\\).\nWhen \\(r\\) is both large and small the nonzero steady state is stable (the derivative at the roots is negative). In the case where three biologically relevant roots exist, the intermediate root is unstable.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\nN_max=13\nN_0=0.1\nq=12\nr_1=0.2\nr_2=0.5\nr_3=0.8\n\nn_vec=np.linspace(0,N_max,100)\n\n\ndef rhssprucebudworm_model_f(x,t,r,q):\n\n  f=r*x*(1-x/q) \n  return f  \ndef rhssprucebudworm_model_g(x,t,r,q):\n\n  g=x**2/(1+x**2)\n  return g  \n\nf_1=rhssprucebudworm_model_f(n_vec,0,r_1,q)\nf_2=rhssprucebudworm_model_f(n_vec,0,r_2,q)\nf_3=rhssprucebudworm_model_f(n_vec,0,r_3,q)\ng=rhssprucebudworm_model_g(n_vec,0,r_1,q)\n\nh_1=rhssprucebudworm_model(n_vec,0,r_1,q)\nh_2=rhssprucebudworm_model(n_vec,0,r_2,q)\nh_3=rhssprucebudworm_model(n_vec,0,r_3,q)\n\nfig, ax = plt.subplots(1,2)\n\nax[0].plot(n_vec, f_1,n_vec, f_2,n_vec, f_3,n_vec,g)\nplt.xlabel('$n$')\nplt.ylabel('$f,g$')\nplt.grid(True)\nax[1].plot(n_vec, h_1,n_vec, h_2,n_vec, h_3)\nplt.xlabel('$n$')\nplt.ylabel('$h$')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nFigure 3.5: RHS of spr. budworm model\n\n\n\n\n\n\n3.4.6 Bifurcation analysis\nThe goal is to identify boundaries of \\(rq\\) parameter space where the stability changes occur and/or the number of steady states changes.\nWe can define points in \\(rq\\) parameter space where bifurcations arise by seeking values of \\(n^*\\) that satisfy \\[\nf(n^*)= g(n^*) \\ \\ \\ \\  f'(n^*)= g'(n^*).\n\\]\nThe first of these equations yields \\[\n  r(1-\\frac{n^*}{q}) = \\frac{n^*}{1+n{^*}^{2}},\n\\tag{3.7}\\] and the latter yields \\[\n-\\frac{r}{q}=\\frac{1}{1+n{^*}^{2}}-\\frac{2n{^*}^{2}}{(1+n{^*})^2} = \\frac{1-n{^*}^{2}}{(1+n{^*}^{2})^2}.\n\\tag{3.8}\\]\nHence \\[\n   \\frac{r}{q}= \\frac{n{^*}^{2}-1}{(1+n{^*}^{2})^2}.\n\\]\nSubstituting for \\(r/q\\) in the first equation yields \\[\nr-\\frac{n{^*}^{2}-1}{(1+n{^*}^{2})^2}n^*=\\frac{n^*}{1+n{^*}^{2}},\n\\] which can be written in the form \\[\nr=\\frac{2n{^*}^{3}}{(1+n{^*}^{2})^2}.\n\\] Substituting for \\(r\\) in Equation 3.7 yields \\[\n\\frac{2n{^*}^{3}}{(1+n{^*}^{2})^2}=\\frac{2n{^*}^{3}}{(1+n{^*}^{2})^2}\\frac{n^*}{q}+\\frac{n^*}{1+n{^*}^2}\n\\] which, after some algebra, yields \\[\nq=\\frac{2n{^*}^3}{n{^*}^{2}-1}.\n\\tag{3.9}\\] Hence a set of points that define bifurcations where three steady states transform to a single steady state are given in parametric form in \\(qr\\) parameter space by \\[\n\\left(\\frac{2n{^*}^3}{n{^*}^{2}-1},\\frac{2n{^*}^{3}}{(1+n{^*}^{2})^2}\\right) \\ \\ \\ \\ \\ \\ \\ n^*&gt;1.\n\\]\n\n\nCode\ndef Computerq(x):\n  r_n_star=2*x**3/(x**2-1)\n  q_n_star=2*x**3/(1+x**2)**2\n  return  r_n_star,q_n_star\n\nn_s_1=np.linspace(1,np.sqrt(3),100)\nn_s_2=np.linspace(np.sqrt(3),200,100)\n\n\nr_1,q_1=Computerq(n_s_1)\nr_2,q_2=Computerq(n_s_2)\n\nfig, ax = plt.subplots(1)\n\nax.plot(r_1, q_1,r_2, q_2)\nplt.xlabel('$r$')\nplt.ylabel('$q$')\nax.set_xlim([0, 100])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\nFigure 3.6: Bifurcations in the rq plane\n\n\n\n\nBy varying values of \\(n^*\\) in Figure 3.6 we plot a region of instability. Note for example that \\(q\\rightarrow \\infty\\) as \\(n^*\\rightarrow 1\\) and as \\(n^*\\rightarrow \\infty\\). Note also that in these limits \\(r\\) must take the value 1/2 and 0, respectively.\nWe can show that the cusp in Figure 3.6 is given by \\[\n\\left(q,r\\right)=\\left(3^{\\frac{3}{2}},\\left(\\frac{\\sqrt{3}}{2}\\right)^3\\right).\n\\]\nNote that \\(r\\) is a decreasing function of \\(q\\) for \\(1&lt;n^*&lt;\\sqrt{3}\\) but that \\(r\\) is an increasing function of \\(n^*\\) for \\(\\sqrt{3}&lt;n^*&lt;\\infty\\). This can be shown by finding the turning points of \\(r\\) w.r.t \\(n^*\\), i.e. Given that \\[\nr=\\frac{2n{^*}^{3}}{(1+n{^*}^{2})^2},\n\\] differentiation with respect to \\(n^*\\) yields \\[\n\\frac{dr}{dn^*}=\\frac{6{n^*}^2}{(1+n^*)^2} - \\frac{8n{^*}^4}{(1+n^*)^3}.\n\\] The turning point satisfies \\[\n\\frac{6{n^*}^2}{(1+n^*)^2} - \\frac{8n{^*}^4}{(1+n^*)^3}=0\n\\] Solving for \\(n^*\\) yields \\[\n6(1+{n^*}^2) - 8n{^*}^2=0\n\\] Hence \\[\n  n^*=\\sqrt{3}.\n\\] Thus there is a turning point that minimises \\(r\\) at \\(n^*=\\sqrt{3}\\).\nSubstitution for this value of \\(n^*\\) yields \\[\n\\left(q,r\\right)=\\left(3^{\\frac{3}{2}},\\left(\\frac{\\sqrt{3}}{2}\\right)^3\\right).\n\\] See Figure 3.6.\n\n\n3.4.7 Hysteresis\nFinally, rearranging the steady-state equation \\[\n  r(1-\\frac{n^*}{q}) = \\frac{n^*}{1+n{^*}^{2}},\n\\] we obtain \\[\n   r = \\frac{n^*}{(1+n{^*}^{2})(1-\\frac{n^*}{q})}.\n\\tag{3.10}\\]\nConsidering \\(n^*&lt;q\\) we compute \\(r\\); plotting \\(n^*\\) against \\(r\\) yields the bifurcation curve presented in Figure 3.7.\n\n\nCode\ndef Computern(x,q):\n  r=x/((1+x**2)*(1-x/q))\n  return  r\n\n\nq=12\nn_s_1=np.linspace(1,np.sqrt(3),100)\nn_s_2=np.linspace(np.sqrt(3),0.99*q,100)\nn_s_3=np.linspace(0,np.sqrt(3),100)\n\n\n\nr_1=Computern(n_s_1,q)\nr_2=Computern(n_s_2,q)\nr_3=Computern(n_s_3,q)\n\nfig, ax = plt.subplots(1)\n\nax.plot(r_1, n_s_1,r_2, n_s_2,r_3,n_s_3)\nplt.xlabel('$r$')\nplt.ylabel('$n^*$')\nax.set_xlim([0, 2])\nplt.grid(True)\n\nplt.show()\n\n\n\n\n\nFigure 3.7: Bifurcations in the rq plane\n\n\n\n\nA system exhibiting hysteresis shows a response to an increases in a control parameter that is not exactly reversed when the parameter is decreased. We can show that the spruce budworm model exhibits hysteresis by considering the argument below.\nSuppose \\(r\\) is initially small (\\(r&lt;r_1\\)). There is only one steady-state and any initial condition will converge towards it.\nSuppose we increase the value of the parameter \\(r\\). There will be a critical value of \\(r\\) (\\(r=r_1\\))where a second stable steady-state arises and the model enters the bistable regime, where there are two possible stable steady-states. Given the system system was originally in the first stable steady state, it will remain there.\nSuppose we continue to increase \\(r\\). Eventually we reach critical value of \\(r\\) (\\(r=r_2\\)) where the first stable steady state is lost and there is again only one stable steady-state.\nSuppose we now decrease the parameter \\(r\\) below the threshold \\(r=r_2\\). The system again enters the bistable regime but as the second solution is stable, it remains the solution.\nSuppose we continue to decrease \\(r\\) until eventually \\(r&lt;r_1\\). We return to the case where the system has only a single stable steady state."
  },
  {
    "objectID": "SinglePopODEMOdels.html#harvesting",
    "href": "SinglePopODEMOdels.html#harvesting",
    "title": "3  Single species population dynamics",
    "section": "3.5 Harvesting",
    "text": "3.5 Harvesting\nBy introducing terms that represent harvesting, population models can be used to investigate management strategies for resource management. The modelling problem is to maximise the sustained yield.\nConsider a model for logistic growth supplemented with a harvesting term \\[\n\\frac{dN}{dt}=rN\\left(1-\\frac{N}{K}\\right) -EN.\n\\] The term \\(EN\\) is the harvesting yield per unit time and the constant \\(E\\) represents the harvesting effort.\nSteady states satisfy \\[\nrN^*\\left(1-\\frac{N^*}{K}\\right) -EN^*=0\n\\] Thus either \\(N^*=0\\) or \\[\n\\left(1-\\frac{N^*}{K}\\right) -E=0\n\\] Hence \\[\nN^*=K(1-\\frac{E}{r}).\n\\] Note that this is positive only if \\[\nE&lt;r.\n\\] Thus if the harvesting rate exceeds the linear growth rate the only steady state corresponds to extinction.\nThe yield is \\[\nY(E)=EN^*=EK(1-\\frac{E}{r})\n\\]\nTo maximise the yields we differentiate with respect to \\(E\\). \\[\n\\frac{dY}{dE} = K - 2\\frac{EK}{r}.\n\\] Thus the maximum yield is identified by setting \\[\n\\frac{dY}{dE} = K - 2\\frac{EK}{r}=0.\n\\] THe maximum occurs at harvesting rate \\[\nE_c=\\frac{r}{2}.\n\\] The maximum yield is \\[\nE^*=\\frac{rK}{4}.\n\\]\nWe identify the time scale over which stocks return to steady state by linearising about the steady state \\(N^*=K(1-E/r)\\), hence \\[\n\\frac{d \\hat{N}}{dt} = (E-r)\\hat{N}.\n\\] Hence the recovery time scale is \\[\nT_R(E)=O(\\frac{1}{r-E}).\n\\] As the harvesting rate approaches the linear growth rate \\(r\\), not only does the steady state population tend to zero but the timescale for stocks to recover tends to infinity. }"
  },
  {
    "objectID": "SinglePopODEMOdels.html#delay-differential-equation-models",
    "href": "SinglePopODEMOdels.html#delay-differential-equation-models",
    "title": "3  Single species population dynamics",
    "section": "3.6 Delay differential equation models",
    "text": "3.6 Delay differential equation models\nConsider a model of the form \\[\n\\frac{dN}{dt}=H(N(t),N(t-T)),\n\\] such that the right-hand side now depends on the value \\(N\\) not just at time \\(t\\) but also at some delay time \\(t-T\\). We now need to prescribe initial conditions of the form \\[\nN(t)=f(t), \\quad -T&lt;t\\leq0.\n\\]\nConsider a simple case of a linear model \\[\n\\frac{dN}{dt}=-N(t-T).\n\\] A steady state, \\(N^*\\), is defined such that \\(N(t)=N(t-T)=N^*\\). Hence \\[\n0=-kN^*.\n\\] The only steady state is \\(N^*=0\\).\nTo compute the linear stability we consider solution of the linearised equation of the form \\[\nN(t)=e^{\\lambda t}.\n\\] Hence \\[\nN(t-T)=e^{\\lambda (t-T)}.\n\\]\nSubstitution yields \\[\n\\lambda  e^{\\lambda t} = - e^{\\lambda (t-T)}.\n\\] Hence the eigenvalue, \\(\\lambda\\), satisfies a transcendental equation \\[\n\\lambda=-e^{\\lambda -T}.\n\\] This equation has no solutions for \\(\\lambda \\in \\Re\\).\nConsider solutions \\(\\lambda \\in \\mathbb{C}\\). Let \\(\\lambda=\\mu+i\\omega\\). Substitution yields \\[\n\\mu+i\\omega = -e^{-\\mu T}(\\cos(\\omega T)-i \\sin(\\omega T)).\n\\] Hence \\[\n\\begin{aligned}\n\\mu=-\\cos(\\omega T)e^{-\\mu T} \\\\\n\\omega = \\sin(\\omega T)e^{-\\mu T}.\n\\end{aligned}\n\\] For linear stability we require that \\(\\mu &lt;0\\). This implies that \\[\n-\\frac{\\pi}{2}&lt;\\omega T &lt; \\frac{\\pi}{2}.\n\\]\nConsider \\[\n\\frac{e^{\\mu T}}{T}=\\frac{\\omega e^{\\mu T}}{\\omega T} = \\frac{\\sin(\\omega T)}{\\omega T}\n\\]\nNoting that \\[\n\\frac{\\sin z}{z} &gt; \\frac{1}{\\frac{\\pi}{2}}\n\\] yields \\[\n\\frac{\\sin(\\omega T)}{\\omega T}&gt;\\frac{2}{\\pi}.\n\\] Hence \\[\n\\frac{e^{\\mu T}}{T} &gt;\\frac{2}{\\pi}.\n\\] Rearranging \\[\nT&lt;\\frac{\\pi}{2}e^{\\mu T}.\n\\] For linear stability \\(\\mu&lt;0\\). Hence a necessary condition for linear stability is that \\[\nT&lt;\\frac{\\pi}{2}\n\\]"
  },
  {
    "objectID": "SinglePopODEMOdels.html#references",
    "href": "SinglePopODEMOdels.html#references",
    "title": "3  Single species population dynamics",
    "section": "3.7 References",
    "text": "3.7 References\n\n\n\n\nLudwig, Donald, Dixon D Jones, Crawford S Holling, et al. 1978. “Qualitative Analysis of Insect Outbreak Systems: The Spruce Budworm and Forest.” Journal of Animal Ecology 47 (1): 315–32."
  },
  {
    "objectID": "ContinuousTimeTwoSepcies.html#general-tools",
    "href": "ContinuousTimeTwoSepcies.html#general-tools",
    "title": "4  Multi species population dynamics",
    "section": "4.1 General tools",
    "text": "4.1 General tools\n\n4.1.1 Steady states\n\\((u^*,v^*)\\) is defined to be a steady state of Equation 4.1 if\n\\[\nf(u^*,v^*)=g(u^*,v^*)=0.\n\\]\nHence, by definition, the time derivatives of \\(u(t)\\) and \\(v(t)\\) are both zero at \\((u^*,v^*)\\). As was the case for single species models, steady states are obtained by solving algebraic equations.\n\n\n4.1.2 Linear stability analysis\nSuppose that \\((u^*,v^*)\\) is a steady state of equations Equation 4.1.\nWe consider a change of dependent variables such that\n\\[\nu(t)=u^*+ \\hat{u}(t)  \\  \\  \\textrm{and} \\ \\ v(t)=v^*+\\hat{v}(t),\n\\]\nwhere \\(\\hat{u}(t)\\) and \\(\\hat{v}(t)\\) are perturbations about the steady state.\nRewriting equation Equation 4.1 in the transformed variables yields\n\\[\n\\begin{aligned}\n\\frac{d\\hat{u}}{dt}&=f(u^*+\\hat{u},v^*+\\hat{v}),  \\nonumber \\\\\n\\frac{d\\hat{v}}{dt}&=g(u^*+\\hat{u},v^*+\\hat{v}).\n\\end{aligned}\n\\tag{4.2}\\]\nMaking Taylor expansions about \\((u^*,v^*)\\) yields the linearised equations\n\\[\n\\begin{aligned}\n\\frac{d\\hat{u}}{dt}=\\frac{\\partial f}{\\partial u}_{|(u^*,v^*)} \\hat{u} +  \\frac{\\partial f}{\\partial v}_{|(u^*,v^*)}  \\hat{v} + h.o.t, \\nonumber\\\\\n\\frac{d\\hat{v}}{dt}=\\frac{\\partial g}{\\partial u}_{|(u^*,v^*)}  \\hat{u} +  \\frac{\\partial g}{\\partial v}_{|(u^*,v^*)}  \\hat{v} + h.o.t. \\nonumber\n\\end{aligned}\n\\tag{4.3}\\]\nUpon making the assumption that the perturbations about the steady state are small, the leading order terms are linear and higher order terms are neglected. Defining\n\\[\n\\mathbf{w}=\\left\n(\\begin{array}{r}\n\\hat{u} \\\\\n\\hat{v}\n\\end{array}\\right),\n\\]\nyields the system of linear ODEs given by\n\\[\n\\frac{d \\mathbf{w}}{dt}= A \\mathbf{w},\n\\tag{4.4}\\]\nwhere the matrix \\(A\\), known as the Jacobian matrix, takes the form\n\\[\nA=\\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial u}&\\frac{\\partial f}{\\partial v} \\\\ \\frac{\\partial g}{\\partial u}&\\frac{\\partial g}{\\partial v} \\end{array}\\right)_{(u^*,v^*)}. \\qquad\n\\]\nThe linear system arrived upon in Equation 4.4 was encountered previously in Differential Equations (MA31002). We summarise the important results here. Seeking a solution of Equation 4.4 of the form\n\\[\n\\mathbf{w}=\\mathbf{v}e^{\\lambda t}\n\\]\none obtains the characteristic equation\n\\[\n\\lambda^2 -\\lambda \\mathrm{tr}(A)+\\det(A)=0,\n\\] which has solutions\n\\[\n\\lambda = \\frac{\\mathrm{tr}{A}\\pm \\sqrt{\\mathrm{tr}{A}^2-4\\det{A}}}{2}.\n\\]\nWhilst a complete classification of the linear stability of a steady state can be obtained by explicitly calculating the eigenvalues, in many cases it is sufficient to deduce whether or not a steady state is stable or unstable. This can be achieved by calculating the determinant and trace of the Jacobian matrix (\\(\\det(A)\\) and \\(\\mathrm{tr}(A)\\), respectively) and referring to Figure 4.1.\n\n\n\nFigure 4.1: Stability in the trace detemrinant plane.\n\n\nThe different cases can be categorised as follows:\n\n\\(\\det(A)&lt;0\\) There is one positive and one negative real eigenvalue. Hence the steady state is a saddle which is unstable.\n\\(\\det(A)&gt;0\\) The steady state can be either stable or unstable, depending on \\(\\mathrm{tr}(A)\\) (and the real part of the eigenvalues).\n\nIf \\(\\mathrm{tr}(A)&gt;0\\), the steady state is unstable.\n\nIf \\(\\mathrm{tr}(A)^2&gt;4 \\det(A)\\), it is an unstable node.\nIf \\(\\mathrm{tr}(A)^2&lt;4 \\det(A)\\) it is an unstable spiral.\n\nIf \\(\\mathrm{tr}(A)&lt;0\\), the steady state is stable.\n\nIf \\(\\mathrm{tr}(A)^2&gt;4 \\det(A)\\), it is an stable node.\nIf \\(\\mathrm{tr}(A)^2&lt;4 \\det(A)\\), it is an stable spiral.\n\n\n\nThese different cases can be distinguished in the trace-determinant plane plotted in Figure 4.1.\nNote that it can be shown rigorously that the linear stability of the nonlinear system is equivalent to that of the linearised system in all cases except when the steady state is a centre. In this case, nonlinear stability analysis is required to determine the stability of the nonlinear system.\nThe condition\\(\\det(A)&gt;0\\) excludes the case that the eigenvalues are real but have opposite signs (i.e. it cannot be a saddle point).\nThe condition \\(\\mathrm{tr}(A)&gt;0\\) implies that the real part of both eigenvalues are positive (i.e. the steady state is unstable).\nThe condition \\(\\mathrm{tr}(A)^2&lt;4 \\det(A)\\) implies that the eigenvalue are complex. Hence \\[\n\\lambda_{\\pm}=\\mu\\pm i\\omega \\ \\ \\\n\\] and the solution of the system can be written \\[\ne^{\\lambda t} = e^{(\\mu+i\\omega) t} = e^{\\mu t}e^{i\\omega t}.\n\\] Thus the magnitude of perturbation grows but it oscillates about the steady state. Hence the steady state is an unstable spiral.\n\n\n4.1.3 Nullclines\nNullclines of the equations Equation 4.1 are given by the curves \\[\nf(u,v)=0\n\\] and \\[\ng(u,v)=0,\n\\] respectively. Note that steady states arise at the intersection of nullclines.\nUsing the \\(u\\) nullclines we identify domains of the phase plane where \\(du/dt &gt;0\\) and \\(du/dt &lt;0\\).\nSimilarly, using the \\(v\\) nullcline we identify domains of the phase plane where \\(dv/dt &gt;0\\) and \\(dv/dt &lt;0\\).\nThe nullclines can be used to help identify confined sets and hence apply the Poincaire-Bendixson theorem.\n\n\n4.1.4 Poincaire-Bendixson theorem\nSuppose that the system of equations \\[\n\\frac{du}{dt}=f(u,v), \\ \\ \\ \\ \\frac{dv}{dt}=g(u,v)\n\\tag{4.5}\\] possesses a confined set (i.e. a bounded domain in the phase plane upon which the derivative field points into the domain) that contains an unstable node or spiral. Any trajectory cannot leave the confined set, nor can it tend to the unstable steady state. The Poincaire-Bendixson theorem states that as \\(t\\rightarrow \\infty\\), the trajectory will tend towards a limit cycle.\n\n\n4.1.5 Dulac criterion\nSuppose \\(D\\) is a simply connected region in the plane and that there exists a function \\(B(x,y)\\), continuously differentiable on \\(D\\), such that the expression \\[\n\\frac{\\partial }{\\partial u} (Bf) + \\frac{\\partial }{\\partial v} (Bg)\n\\] is not identically zero and does not change sign in D. Then there are no closed orbits in \\(D\\)."
  },
  {
    "objectID": "ContinuousTimeTwoSepcies.html#the-lotka-voltera-model",
    "href": "ContinuousTimeTwoSepcies.html#the-lotka-voltera-model",
    "title": "4  Multi species population dynamics",
    "section": "4.2 The Lotka-Voltera model",
    "text": "4.2 The Lotka-Voltera model\nSuppose that \\(N(t)\\) and \\(P(t)\\) represent the prey and predator population densities at time \\(t\\), respectively. Consider a model of the form \\[\n   \\begin{aligned}\n   \\frac{dN }{dt} &= aN -bNP, \\nonumber \\\\\n      \\frac{dP }{dt} &= cNP -dP,\n\\end{aligned}\n\\] where \\(a\\), \\(b\\), \\(c\\) and \\(d\\) are positive constants.\n\n4.2.1 Nondimensionalisation\nNondimensionalising with \\[\nn=\\frac{N}{\\tilde{N}}, \\ \\ \\ \\ p=\\frac{P}{\\tilde{P}}  \\ \\ \\textrm{and} \\ \\ \\tau= \\frac{t}{\\tilde{T}},\n\\]\nyields, after changing variables, \\[  \n\\begin{aligned}\n   \\frac{dn }{d\\tau} &= \\tilde{T}an -b\\tilde{T} \\tilde{P}np,  \\nonumber \\\\\n      \\frac{dp }{d\\tau} &= c\\tilde{N} \\tilde{T}np -d\\tilde{T}p.\n\\end{aligned}\n\\] Choosing the dimensional scalings\n\\[\n\\tilde{T}=1/a, \\ \\ \\ \\tilde{P}=a/b  \\ \\ \\ \\textrm{and} \\ \\ \\ \\tilde{N}=d/c,\n\\]\nyields\n\\[\n\\begin{aligned}\n\\frac{dn }{d\\tau} &= n(1-p) = f(n,p), \\nonumber \\\\\n\\frac{dp }{d\\tau} &=\\alpha p(n-1)  = g(n,p),\n\\end{aligned}\n\\tag{4.6}\\]\nwhere \\(\\alpha=d/a\\). Note that all variables and parameter are without dimensions.\n\n\n4.2.2 Numerical solutions\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\nalpha=1.5\ndef rhs_lv_model(x,t):\n  rhs=np.zeros_like(x)\n  n=x[0]\n  p=x[1]\n  dn_dt=n*(1-p)\n  dp_dt=alpha*p*(n-1)\n  rhs[0]=dn_dt\n  rhs[1]=dp_dt\n  return rhs\n\nt = np.linspace(0, 10, 1000)\n\ninit_cond=[0.5,0.5]\nalpha=2.0\nsol1 = odeint(rhs_lv_model, init_cond,t)\n\n\nn=sol1[:,0]\np=sol1[:,1]\n\nplt.plot(t, n, 'b',t,p,'r')\n\nplt.legend(['n','p'],loc='best')\nplt.xlabel('t')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.2: Numerical solution of Lotka-Volterra model\n\n\n\n\n\n\n4.2.3 Steady states\nThe steady-states of equation Equation 4.6 are identified by seeking solutions of\n\\[\nf(n^*,p^*)=g(n^*,p^*)=0.\n\\]\nHence\n\\[\nn^*(1-p^*)= 0 \\ \\ \\ \\ \\ \\alpha p^*(n^*-1).\n\\]\nThe first of these equations has solutions either\n\\[\nn^*=0 \\ \\ \\  \\textrm{or} \\ \\ \\  p^* =1.\n\\]\nSubstituting for \\(n^*=0\\) in the second equation yields \\(p^*=0\\). Hence one steady state is \\((0,0)\\). Substituting for \\(p^*=1\\) in the second equation yields \\(n^*=1\\). Hence a second steady state is (1,1).\n\n\n4.2.4 Linear stability\nThe linear stability of the steady states is described by the Jacobian matrix \\[\nA=\\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial n}&\\frac{\\partial f}{\\partial p} \\\\ \\frac{\\partial g}{\\partial n}&\\frac{\\partial g}{\\partial p} \\end{array}\\right)_{(n^*,p^*)} = \\left(\\begin{array}{rr}\n1-p&-n \\\\ \\alpha p &\\alpha (n-1) \\end{array}\\right)_{(n^*,p^*)}\n\\]\nEvaluating at (0,0) yields\n\\[\nA=\\left(\\begin{array}{rr} 1&0 \\\\ 0 &-\\alpha \\end{array}\\right),\n\\]\nHence the eigenvalues of \\(A\\) are \\(1\\) and \\(-\\alpha\\). As \\(\\alpha&gt;0\\) the origin is a saddle. The eigenvectors are \\([1, 0]\\) and $[0,1]. $\nAt (1,1) \\[\nA=\\left(\\begin{array}{rr} 0&-1 \\\\ \\alpha &0 \\end{array}\\right),\n\\]\nand the eigenvalues are \\(\\pm i\\sqrt{\\alpha}\\). Therefore the steady state at (1,1) is a centre.\n\n\n4.2.5 Solutions in the phase plane\nSee Figure 4.3 for solution trajectories plotted in the phase plane using different initial conditions. Note the expected saddle like behaviour when trajectories that are close to the origin. Furthermore, note that the different initial conditions result in distinct closed loops and that the inner-most loop, i.e. that closest to the steady-state (1,1), behaves like a centre, as expected given the linear stability analysis. However, far from the steady-state the solution trajectory deviates from the linearised model.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\nalpha=1.5\ndef rhs_lv_model(x,t):\n  rhs=np.zeros_like(x)\n  n=x[0]\n  p=x[1]\n  dn_dt=n*(1-p)\n  dp_dt=alpha*p*(n-1)\n  rhs[0]=dn_dt\n  rhs[1]=dp_dt\n  return rhs\n\n\nt = np.linspace(0, 10, 1000)\n\ninit_cond1=[0.75,0.75]\ninit_cond2=[0.15,0.15]\ninit_cond3=[2.5,0.5]\n\nalpha=2.0\nsol1 = odeint(rhs_lv_model, init_cond1,t)\nsol2 = odeint(rhs_lv_model, init_cond2,t)\nsol3 = odeint(rhs_lv_model, init_cond3,t)\n\nn=sol1[:,0]\np=sol1[:,1]\n\nss=[1,1]\n\nplt.plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nplt.plot(ss[0],ss[1],'k*')\nplt.xlabel('$n$')\nplt.ylabel('$p$')\n\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.3: Numerical solution of Lotka-Volterra model\n\n\n\n\n\n\n4.2.6 Direct integration\nThe Lotka-Volterra equations are a special case as they are integrable. Trajectories in the phase plane satisfy the differential equation\n\\[\n\\frac{dp }{d n} = \\frac{\\alpha p (n-1)}{n(1-p)},\n\\]\nUsing separation of variables\n\\[\n\\int \\frac{1-p}{p} dp  = \\alpha  \\int \\frac{n-1}{n} dn.  \n\\]\nIntegration yields\n\\[\n\\ln p - p =  \\alpha (n-\\ln n) + H,\n\\]\nwhere \\(H\\) is a conserved quantity that this is determined by the initial conditions. As the equations take conservative form, the Lotka-Voltera model is said to be structurally unstable, as a small perturbation to the solution at a given point in the oscillatory cycle can result in large changes elsewhere in the cycle. For example, suppose the outermost limit cycle in Figure 4.3 is perturbed by a small amount at the point (1,0.1) onto its nearest limit cycle. Later in the cycle these two trajectories deviate by a large amount."
  },
  {
    "objectID": "ContinuousTimeTwoSepcies.html#competition",
    "href": "ContinuousTimeTwoSepcies.html#competition",
    "title": "4  Multi species population dynamics",
    "section": "4.3 Competition",
    "text": "4.3 Competition\nIn models of competition, two or more species compete for the same resource or in some way inhibit each other’s growth. Letting \\(N_1(t)\\) and \\(N_2(t)\\) represent the population density of two species, we consider the ODEs \\[\n\\begin{aligned}\n\\frac{d N_1}{dt} &= r_1N_1\\left(1-\\frac{N_1}{K_1}-b_{12}\\frac{N_2}{K_1}\\right), \\nonumber \\\\\n\\frac{d N_2}{dt} &= r_2N_2\\left(1-\\frac{N_2}{K_2}-b_{21}\\frac{N_1}{K_2}\\right),\n\\end{aligned}\n\\] where \\(r_1\\), \\(r_2\\), \\(K_1\\) and \\(K_2\\) are positive constants. As before, the \\(r's\\) are linear growth rates and the \\(K\\)’s are carrying capacities. The parameters \\(b_{12}\\) and \\(b_{21}\\) measure the competitive effect of \\(N_2\\) on \\(N_1\\) and \\(N_1\\) on \\(N_2\\), respectively.\n\n4.3.1 Nondimensionalisation\nAfter nondimensionalising using the change of variables\n\\[\nn_1=\\frac{N_1}{K_1} \\ \\ n_2=\\frac{N_2}{K_2} \\ \\ \\tau=\\frac{t}{\\frac{1}{r_1}},\n\\]\nwe obtain the equations\n\\[\n\\begin{aligned}\n\\frac{d n_1}{d\\tau} &= n_1\\left(1- n_1-a_{12}n_2\\right) = f(n_1,n_2), \\nonumber \\\\\n\\frac{d n_2}{d\\tau} &= \\rho n_2\\left(1-n_2-a_{21}n_1\\right) =g(n_1,n_2),\n\\end{aligned}\n\\tag{4.7}\\]\nwhere\n\\[\n\\rho=\\frac{r_2}{r_1}, \\ \\ \\ a_{12}=b_{12}\\frac{K_2}{K_1}, \\ \\ \\  a_{21}=b_{21}\\frac{K_1}{K_2}.\n\\]\n\n\n4.3.2 Steady states\nThe steady states of Equation 4.7 are identified in the usual manner, i.e. by seeking \\(({n_1}^*,{n_2}^*)\\) such that\n\\[\nf({n_1}^*,{n_2}^*)=g({n_1}^*,{n_2}^*)=0.\n\\]\nThe steady state equations are \\[\n{n_1}^*\\left(1- {n_1}^*-a_{12}{n_2}^*\\right)=0 \\ \\ \\ \\ {n_2}^*\\left(1-{n_2}^*-a_{21}{n_1}^*\\right)=0.\n\\] The first equation has solution \\[\nn_1^*=0\n\\] or \\[\n\\left(1- {n_1}^*-a_{12}{n_2}^*\\right) \\implies n_2=\\frac{1}{a_{12}}(1-n_1^*).\n\\] Consider \\(n_1^*=0\\). Substitution in the second equation yields \\[\n{n_2}^*\\left(1-{n_2}^*\\right)=0.\n\\] Hence either \\(n_2^*=0\\) or \\(n_2^*=1\\). Hence two steady states are \\((0,0)\\) and \\((0,1).\\) \\ Now consider \\(n_2^*=\\frac{1}{a_{12}}(1-n_1^*)\\) with \\(n_1^*\\neq0\\). \\ Substitution in the second steady state equation yields \\[\n\\frac{1}{a_{12}}(1-n_1^*) \\left(1- \\frac{1}{a_{12}}(1-n_1^*) -a_{21}{n_1}^*\\right)\n\\] Hence either \\(n_1^*=1\\) or \\[\n\\left(1- \\frac{1}{a_{12}}(1-n_1^*) -a_{21}{n_1}^*\\right)=0 \\implies n_1^*=\\frac{1-a_{12}}{1-a_{12}a_{21}}.\n\\] In the case where \\(n_1^*=1\\), we find that \\(n_2^*=0\\). Hence the steady state is (1,0).\nIn the case where \\[\nn_1^*=\\frac{1-a_{12}}{1-a_{12}a_{21}}\n\\] we find that \\[\nn_2^*=\\frac{1-a_{21}}{1-a_{12}a_{21}}\n\\] Hence the steady state is \\[\n\\left(\\frac{1-a_{12}}{1-a_{12}a_{21}},\\frac{1-a_{21}}{1-a_{12}a_{21}}\\right).\n\\]\n\n\n4.3.3 Nullclines\nThe nullclines for Equation 4.7 are straight lines given by\n\\[\nn_1=0 \\ \\ \\ \\ \\ n_2=\\frac{1-n_1}{a_{12}},\n\\]\nand\n\\[\nn_2=0 \\ \\  \\ \\  \\ n_2= 1-a_{21}n_1.\n\\]\nNote that the steady states \\((0,0)\\), \\((1,0)\\) and \\((0,1)\\) are always biologically relevant (i.e. independently of the parameter values for \\(a_{12}\\) and \\(a_{21}\\)).\nHowever, the coexistence steady state is only biologically relevant if the nullclines intersect in the positive quadrant and this occurs only in certain regions of the model’s parameter space.\nIn the cases where \\(a_{12},a_{21}&lt;1\\) and \\(a_{12},a_{21}&gt;1\\) there is a coexistence steady state (i.e. the nullclines intersect in the positive quadrant).\nHowever, if \\(a_{21}&lt;1\\) and \\(a_{12}&gt;1\\) or \\(a_{12}&lt;1\\) and \\(a_{21}&gt;1\\) there is not a biologically relevant, coexistence steady state (i.e. the nullclines do not intersect in the positive quadrant).\nHence there are are four qualitatively different types of solution to consider.\n\n\n4.3.4 Linear stability\nThe linear stability of the different steady states is determined by calculating the Jacobian matrix\n\\[\nA=\\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial n_1}&\\frac{\\partial f}{\\partial n_2} \\\\ \\frac{\\partial g}{\\partial n_1 }&\\frac{\\partial g}{\\partial n_2} \\end{array}\\right)_{({n_1}^*,{n_2}^*)} = \\left(\\begin{array}{rr}\n1-2n_1 -a_{12}n_2&-a_{12}n_1 \\\\ -\\rho a_{21}n_2 &\\rho(1-2n_2-a_{21}n_1)\\end{array}\\right)_{({n_1}^*,{n_2}^*)}.\n\\]\nAt (0,0)\n\\[\nA=\\left(\\begin{array}{rr}\n1& 0 \\\\ 0 & \\rho\\end{array}\\right).\n\\]\nHence the eigenvalues of the Jacobian are \\(1\\) and \\(\\rho\\). As \\(\\rho&gt;0\\), the origin is therefore an unstable node (there are two real positive eigenvalues).\nAt (1,0)\n\\[\nA=\\left(\\begin{array}{rr}\n-1& -a_{12} \\\\ 0 & \\rho(1-a_{21})\\end{array}\\right).\n\\]\nThe trace and determinant are given by\n\\[\n\\det{A}=\\rho  (a_{21}-1)\\ \\ \\ \\textrm{and} \\ \\ \\ \\mathrm{tr}{A}=-1+\\rho(1-a_{21}).\n\\]\nHence if \\(a_{21}&lt;1\\), \\(\\det{A}&lt;0\\) and (1,0) is a saddle point and thus unstable (see Figure 4.1).\nIf \\(a_{21}&gt;1\\), \\(\\det{A}&gt;0\\) and \\(\\mathrm{tr}{A}&lt;0\\). Hence (1,0) is a stable node.\nHence the parameter \\(a_{21}\\), which describes how strongly Population 1 inhibits the growth rate of Population 2, determines whether or not the steady state representing extinction of Population 2 but not Population 1 is stable or not.\nAt (0,1)\n\\[\nA=\\left(\\begin{array}{rr}\n1-a_{12}& 0\\\\  -\\rho a_{21} & -\\rho \\end{array}\\right).\n\\]\nIn this case if \\(a_{12}&lt;1\\), \\(\\det{A}&lt;0\\) and (0,1) is a saddle point. If \\(a_{12}&gt;1\\), \\(\\det{A}&gt;0\\) and \\(\\mathrm{tr}{A}&lt;0\\) and (0,1) is a stable node. Hence the parameter \\(a_{12}\\), which describes how strongly Population 2 inhibits the growth rate of Population 1, determines whether or not the steady state representing extinction of Population 1 but not Population 2 is stable or not.\nAt the coexistence steady state, recall the steady state is\n\\[\n\\left(\\frac{1-a_{12}}{1-a_{12}a_{21}},\\frac{1-a_{21}}{1-a_{12}a_{21}}\\right).\n\\] Note that this steady state is only biologically relevant in the cases \\(a_{21}&lt;1, a_{12}&lt;1\\) or \\(a_{21}&gt;1, a_{12}&gt;1\\). Evaluating the Jacobian yields \\[\nA=\\frac{1}{1-a_{12}a_{21}}\\left(\\begin{array}{rr}\na_{12}-1  & -a_{12}(1-a_{12})\\\\ -\\rho a_{21}(1-a_{21}) &\\rho(a_{21}-1)\\end{array}\\right).\n\\]\nThe determinant and trace of the Jacobian are given by\n\\[\n\\begin{aligned}\n\\det{A}&=\\rho\\left((a_{12}-1)(a_{21}-1)-a_{12}a_{21}(1-a_{12})(1-a_{21})\\right)\\frac{1}{(1-a_{12}a_{21})^2}, \\nonumber \\\\\n&= \\rho\\frac{(a_{12}-1)(a_{21}-1)}{(1-a_{12}a_{21})},\n\\end{aligned}\n\\]\nand\n\\[\n\\mathrm{tr}{A}=\\left(a_{12}-1+\\rho(a_{21}-1)\\right) \\frac{1}{1-a_{12}a_{21}},\n\\] respectively. \\stwriting{\nLet’s firstly consider the case where \\(a_{21}&lt;1\\) and \\(a_{21}&lt;1\\). This implies that \\(a_{21}-1&lt;0\\) and \\(a_{12}-1&lt;0\\), hence evaluating the signs of the different products yields\n\\[\n\\det{A} = \\rho(-)(-)(+)&gt;0\n\\] and \\[\n\\mathrm{tr}{A}= \\rho(-) + (-)&lt;0.\n\\]\nTherefore the coexistence steady state is a stable node or spiral.\nIn the case where \\(a_{21}&gt;1\\) and $a_{12}&gt;1\n\\[\n\\det{A} = \\rho(+)(+)(-)&lt;0 .\n\\]\nHence the coexistence steady state is a saddle.\n\n\n4.3.5 Phase portrait\nSee Figure 4.5 for phase portraits of three of the four cases that we have considered. It is expected that you can sketch phase portraits. Key details to consider are the steady states and their linear stability. You should also sketch the nullclines and depict the sign of the derivatives in the phase plane on either side of the nullclines. You should also sketch one or more sample trajectories.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\nrho=1.5\na_12=0.5\na_21=0.5\ndef rhs_comp_model(x,t):\n  rhs=np.zeros_like(x)\n  n_1=x[0]\n  n_2=x[1]\n  dn_1_dt=n_1*(1-n_1)-a_12*n_1*n_2\n  dn_2_dt=rho*(n_2*(1-n_2)-a_21*n_1*n_2)\n  rhs[0]=dn_1_dt\n  rhs[1]=dn_2_dt\n  return rhs\n\nt = np.linspace(0, 10, 1000)\n\ninit_cond=[0.5,0.5]\nsol1 = odeint(rhs_comp_model, init_cond,t)\n\n\nn_1=sol1[:,0]\nn_2=sol1[:,1]\n\nplt.plot(t, n_1, 'b',t,n_2,'r')\n\nplt.legend(['$n_1$','$n_2$'],loc='best')\nplt.xlabel('t')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.4: Numerical solutions of competition model\n\n\n\n\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\n\nn_1_vec=np.linspace(0,5,100)\n\ndef ComputeCompetitionSol(a_12,a_21,n_1_vec):\n    t = np.linspace(0, 10, 1000)\n\n    init_cond1=[0.75,0.75]\n    init_cond2=[0.15,0.15]\n    init_cond3=[2.5,0.5]\n\n    alpha=2.0\n    sol1 = odeint(rhs_comp_model, init_cond1,t)\n    sol2 = odeint(rhs_comp_model, init_cond2,t)\n    sol3 = odeint(rhs_comp_model, init_cond3,t)\n\n    num_steady_states=3\n    fourth_ss_condition= ((a_12&lt;1) & (a_21&lt;1)) | ((a_12&gt;1) & (a_21&gt;1))\n    if fourth_ss_condition==True:\n        num_steady_states=4\n\n    ss=np.zeros((num_steady_states,2),dtype=float)\n    ss[0,:]=[0,0]\n    ss[1,:]=[1,0]\n    ss[2,:]=[0,1]\n    if fourth_ss_condition==True:\n        ss[3,:]=[(1-a_12)/(1-a_12*a_21),(1-a_21)/(1-a_12*a_21)]\n\n\n    n1_ncline_1_n_1=[0,0]    \n    n1_ncline_1_n_2=[0,5]   \n    n1_ncline_2_n_2=1/a_12*(1-n_1_vec)\n    n2_ncline_1_n_1=[0,5]    \n    n2_ncline_1_n_2=[0,0]   \n    n2_ncline_2_n_2=1-a_21*(n_1_vec)\n\n    return sol1,sol2,sol3,ss,n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2\n\n\na_12=0.5\na_21=0.4\nsol1,sol2,sol3,ss, n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2=ComputeCompetitionSol(a_12,a_21,n_1_vec)\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(n1_ncline_1_n_1,n1_ncline_1_n_2,'k--')\nax[0].plot(n_1_vec,n1_ncline_2_n_2,'k--')\nax[0].plot(n2_ncline_1_n_1,n2_ncline_1_n_2,'r--')\nax[0].plot(n_1_vec,n2_ncline_2_n_2,'r--')\n\nax[0].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[0].plot(ss[:,0],ss[:,1],'k*')\nplt.xlabel('$n_1$')\nplt.ylabel('$n_2$')\n\nax[0].set_xlim([-0.05,1.5])\nax[0].set_ylim([-0.05,1.5])\n\na_12=1.5\na_21=0.4\nsol1,sol2,sol3,ss, n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2=ComputeCompetitionSol(a_12,a_21,n_1_vec)\nax[1].plot(n1_ncline_1_n_1,n1_ncline_1_n_2,'k--')\nax[1].plot(n_1_vec,n1_ncline_2_n_2,'k--')\nax[1].plot(n2_ncline_1_n_1,n2_ncline_1_n_2,'r--')\nax[1].plot(n_1_vec,n2_ncline_2_n_2,'r--')\n\nax[1].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[1].plot(ss[:,0],ss[:,1],'k*')\nplt.xlabel('$n_1$')\nplt.ylabel('$n_2$')\n\nax[1].set_xlim([-0.05,1.5])\nax[1].set_ylim([-0.05,1.5])\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.5: Numerical solution of the competition model\n\n\n\n\n\n\n4.3.6 Insight\nThe model therefore has four qualitatively different behaviours that are described as follows: Consider the case where \\(a_{21}&gt;1\\). This represents the case of Population 1 strongly competing with Population 2.\n\nIf \\(a_{12}&gt;1\\), Population 2 also strongly competes with Population 1. In this case, there are four biologically relevant steady states, two of which are stable (1,0) and (0,1). The coexistence steady state is a saddle and thus unstable. The model is bistable and the initial conditions determine whether solutions end up at (1,0) or (0,1) (see Figure 4.5). The biological interpretation of this solution is that one species will always win and completely outcompete the other. Even if the two populations are equal (\\(K_1=K_2\\) and \\(a_{21}=a_{12}&gt;1\\)), one species will always win and the other will become extinct.\nIf \\(a_{12}&lt;1\\), Population 2 weakly competes with Population 1. There is no coexistence steady state and the only stable steady state is (1,0). Hence Population 1 always wins and Population 2 always becomes extinct.\n\nNow consider the case where \\(a_{21}&lt;1\\). This represents the case of Population 1 weakly competing with Population 2.\n\nIf \\(a_{12}&gt;1\\), Population 2 strongly competes with Population 1. There is nonexistence steady state and the only stable steady state is (0,1). Hence Population 2 always wins and Population 1 always becomes extinct.\nIf \\(a_{12}&lt;1\\), Population 2 also weakly competes with Population 1. The coexistence steady state is stable and the steady states (1,0) and (0,1) are unstable."
  },
  {
    "objectID": "ContinuousTimeTwoSepcies.html#symbiosismutualism",
    "href": "ContinuousTimeTwoSepcies.html#symbiosismutualism",
    "title": "4  Multi species population dynamics",
    "section": "4.4 Symbiosis/Mutualism",
    "text": "4.4 Symbiosis/Mutualism\nWhen the interactions between two species results in mutually benefit, it is known as mutualism or symbiosis. To study this behaviour, we consider a model of the form \\[\n\\begin{aligned}\n\\frac{d N_1}{dt} &= r_1N_1\\left(1-\\frac{N_1}{K_1}+b_{12}\\frac{N_2}{K_1}\\right), \\nonumber \\\\\n\\frac{d N_2}{dt} &= r_2N_2\\left(1-\\frac{N_2}{K_2}+b_{21}\\frac{N_1}{K_2}\\right).\n\\end{aligned}\n\\] Note the only difference with the competition model is that the sign of the interaction term has changed. Hence we will not work through all the details as the analysis is the same as before.\n\n4.4.1 Nondimensionalisation\nUsing the same nondimensionalisation as the competition model, we obtain the nondimensional equations \\[\\begin{aligned}\n\\frac{d n_1}{d\\tau} &= n_1(1- n_1+a_{12}n_2) = f(n_1,n_2), \\nonumber \\\\\n\\frac{d n_2}{d\\tau} &= \\rho n_2(1-n_2+a_{21}n_1) =g(n_1,n_2).\n\\end{aligned}\n\\tag{4.8}\\]\n\n\n4.4.2 Steady states\nThis model has steady-states \\((0,0)\\), \\((1,0)\\),\\((0,1)\\) and\n\\[\n\\left({n_1}^*,{n_2}^*\\right)=\\left(\\frac{1+a_{12}}{1-a_{12}a_{21}},\\frac{1+a_{21}}{1-a_{12}a_{21}}\\right).\n\\] The coexistence steady state is biological relevant if \\(a_{12}a_{21}&lt;1\\)\n\n\n4.4.3 Nullclines\nThe \\(n_1\\) nullclines satisfy \\[\nn_1=0, \\ \\ \\ n_2=\\frac{1}{a_{12}}(n_1-1).\n\\] The \\(n_2\\) nullclines satisfy \\[\nn_2=0, \\ \\ \\ n_2=1+a_{21}n_1.\n\\] Note that both nullclines have a positive slope.\n\n\n4.4.4 Linear stability\nUsing a similar analysis to the competition model, it can be shown that the steady states (0,0), (1,0) and (0,1) are unstable. When \\(a_{12}a_{21}&lt;1\\) there is a stable coexistence steady state. See Figure 4.6.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\n\nn_1_vec=np.linspace(0,5,100)\n\ndef rhs_sym_model(x,t):\n  rhs=np.zeros_like(x)\n  n_1=x[0]\n  n_2=x[1]\n  dn_1_dt=n_1*(1-n_1)+a_12*n_1*n_2\n  dn_2_dt=rho*(n_2*(1-n_2)+a_21*n_1*n_2)\n  rhs[0]=dn_1_dt\n  rhs[1]=dn_2_dt\n  return rhs\n\ndef ComputeSymbiosisSol(a_12,a_21,n_1_vec):\n    t = np.linspace(0, 4, 1000)\n\n    init_cond1=[0.75,0.75]\n    init_cond2=[0.15,0.15]\n    init_cond3=[2.5,0.5]\n\n    alpha=2.0\n    sol1 = odeint(rhs_sym_model, init_cond1,t)\n    sol2 = odeint(rhs_sym_model, init_cond2,t)\n    sol3 = odeint(rhs_sym_model, init_cond3,t)\n\n    num_steady_states=3\n    fourth_ss_condition= ((a_12*a_21&lt;1))\n    if fourth_ss_condition==True:\n        num_steady_states=4\n\n    ss=np.zeros((num_steady_states,2),dtype=float)\n    ss[0,:]=[0,0]\n    ss[1,:]=[1,0]\n    ss[2,:]=[0,1]\n    if fourth_ss_condition==True:\n        ss[3,:]=[(1+a_12)/(1-a_12*a_21),(1+a_21)/(1-a_12*a_21)]\n\n\n    n1_ncline_1_n_1=[0,0]    \n    n1_ncline_1_n_2=[0,5]   \n    n1_ncline_2_n_2=1/a_12*(n_1_vec-1)\n    n2_ncline_1_n_1=[0,5]    \n    n2_ncline_1_n_2=[0,0]   \n    n2_ncline_2_n_2=1+a_21*(n_1_vec)\n\n    return sol1,sol2,sol3,ss,n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2\n\n\na_12=0.5\na_21=0.4\nsol1,sol2,sol3,ss, n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2=ComputeSymbiosisSol(a_12,a_21,n_1_vec)\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(n1_ncline_1_n_1,n1_ncline_1_n_2,'k--')\nax[0].plot(n_1_vec,n1_ncline_2_n_2,'k--')\nax[0].plot(n2_ncline_1_n_1,n2_ncline_1_n_2,'r--')\nax[0].plot(n_1_vec,n2_ncline_2_n_2,'r--')\n\nax[0].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[0].plot(ss[:,0],ss[:,1],'k*')\nplt.xlabel('$n_1$')\nplt.ylabel('$n_2$')\n\nax[0].set_xlim([-0.05,2.5])\nax[0].set_ylim([-0.05,2.5])\n\na_12=1.5\na_21=0.8\nsol1,sol2,sol3,ss, n1_ncline_1_n_1,n1_ncline_1_n_2,n1_ncline_2_n_2,n2_ncline_1_n_1,n2_ncline_1_n_2,n2_ncline_2_n_2=ComputeSymbiosisSol(a_12,a_21,n_1_vec)\nax[1].plot(n1_ncline_1_n_1,n1_ncline_1_n_2,'k--')\nax[1].plot(n_1_vec,n1_ncline_2_n_2,'k--')\nax[1].plot(n2_ncline_1_n_1,n2_ncline_1_n_2,'r--')\nax[1].plot(n_1_vec,n2_ncline_2_n_2,'r--')\n\nax[1].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[1].plot(ss[:,0],ss[:,1],'k*')\nplt.xlabel('$n_1$')\nplt.ylabel('$n_2$')\n\nax[1].set_xlim([-0.05,2.5])\nax[1].set_ylim([-0.05,2.5])\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 4.6: Numerical solution of the symbiosis model\n\n\n\n\n\n\n4.4.5 Insight\nThe important parameter in the model is the product \\(a_{12}a_{21}\\). This quantifies the total amount of cooperativity in the model. All steady states that involve the extinction of a species are unstable. In the case where if \\(a_{12}a_{21}&lt;1\\) there is a stable steady state. Note that steady states of both variables are higher than they would be in the absence of the other species. In the \\(a_{12}a_{21}&gt;1\\) there is no coexistence steady state and both populations grow in an unbounded manner."
  },
  {
    "objectID": "enzymekinetics.html#the-law-of-mass-action",
    "href": "enzymekinetics.html#the-law-of-mass-action",
    "title": "5  Biochemical kinetics",
    "section": "5.1 The law of mass action",
    "text": "5.1 The law of mass action\nWe denote the \\(i^{th}\\) chemical species using the notation \\(C_i\\). The concentration of molecule type \\(C_i\\) is denoted \\([C_i]\\) and represents the number of molecules of \\(C_i\\) per unit volume.\nSuppose \\(C_1,..C_M\\) undergo the reaction\n\\[\n\\lambda_1C_1+\\lambda_2 C_2+...+\\lambda_m C_M \\xrightleftharpoons[k_{b}]{k_{f}}\n\\gamma_1 C_1+\\gamma_2 C_2 + ... \\gamma_M C_M.\n\\]\nthe law of mass action states that the forward reaction proceeds at rate\n\\[\nk_f[C_1]^\\lambda_1 [C_2]^\\lambda_2 ..[C_M]^\\lambda_M\n\\]\nwhilst the backward reaction proceeds at rate\n\\[\nk_b[C_1]^\\gamma_1[C_2]^\\gamma_2 ..[C_M]^\\gamma_M\n\\]\nwhere \\(k_f\\) and \\(k_b\\) are dimensional rate constants.\n\n\n\n\n\n\nExample\n\n\n\nSuppose A and B react to produce C. Hence \\[\nA+B\\xrightarrow{k}  C.\n\\]\nThe law of mass action states that the rate of the reaction is\n\\[\nk[A][B].\n\\]\nUsing the reaction rates, we write down ordinary differential equations that describe how concentrations of a given molecule will change in time. Hence\n\\[\n\\frac{d[C]}{dt}=k[A][B].\n\\]\n\n\n\n\n\n\n\n\nExample\n\n\n\nConsider the reversible reaction \\[\nA+B  \\xrightleftharpoons[k_{-}]{k_{+}}  C.\n\\] Define dependent variables, identify reaction rates and derive ordinary differential equations that describe how concentrations evolved in time.\nThe dependent variables are: \\[ [A](t), \\ \\ [B](t), \\ \\ [C](t) \\].\nApplying the law of mass action yields the reaction rates:\n\\[ k_+[A][B] \\ \\ \\textrm{and} \\ \\ k_-[C]\\].\nThe ODEs are\n\\[\n\\begin{aligned}\n\\frac{d[A]}{dt}&=-k_+[A][B]+k_-[C], \\nonumber\\\\\n\\frac{d[B]}{dt}&=-k_+[A][B]+k_-[C], \\nonumber\\\\\n\\frac{d[C]}{dt}&=k_+[A][B]-k_-[C]. \\nonumber\n\\end{aligned}\n\\]\nFor a given set of initial conditions, \\[\n[A](t=0)=[A]_0, \\ \\ \\ [B](t=0)=[B]_0, \\ \\ \\ [C](t=0)=[C]_0,\n\\] the ODEs can be solved and hence the concentrations of the different molecules described as time evolves.\n\n\n\n5.1.1 Example\nThe previous example have had stochiometric constants all set to unity (i.e. all reactions involved a molecules of one species interaction with one from another). Consider the reaction in which one molecule of species A with \\(m\\) of species B giving rise to \\(n\\) molecules of species B and \\(p\\) molecules of species C, i.e. \\[\nA+mB \\xrightarrow{k_1} nB + pC.\n%X \\underset{k_2}{\\stackrel{k_1}{\\rightleftharpoons}} Y\n\\]\nThe law of mass action says that the rate of the forward reaction is \\[\nk_1[A][B]^m.\n\\]\nThe governing ODEs are \\[\n\\begin{aligned}\n\\frac{d[A]}{dt}&=-k_1[A][B]^m, \\nonumber\\\\\n\\frac{d[B]}{dt}&=(n-m)k_1[A][B]^m, \\nonumber\\\\\n\\frac{d[C]}{dt}&=pk_1[A][B]^m.  \\nonumber\n\\end{aligned}\n\\]\n\n\n\n\n\n\nExample\n\n\n\nConsider the reversible reaction \\[\nA+A  \\xrightleftharpoons[k_{-}]{k_{+}}  B.\n\\] Define dependent variables, identify reaction rates and derive ordinary differential equations that describe how concentrations evolved in time.\nThe reaction rates are \\[\nk_+[A]^2\n\\] and \\[\nk_- [B].\n\\] The ODEs are \\[\n\\begin{aligned}\n\\frac{d[A]}{dt}&=-2k_+[A]^2+2k_- [B] , \\nonumber\\\\\n\\frac{d[B]}{dt}&=k_+[A]^2-k_- [B],\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "enzymekinetics.html#enzyme-kinetics",
    "href": "enzymekinetics.html#enzyme-kinetics",
    "title": "5  Biochemical kinetics",
    "section": "5.2 Enzyme kinetics",
    "text": "5.2 Enzyme kinetics\nBiochemical reactions are often regulated by enzymes (substances that convert a substrate into another substrate). Consider a chemical reaction in which substrate, \\(S\\), reacts with an enzyme, \\(E\\), to form a complex, \\(C\\). Suppose the complex can either undergo the reverse reaction or go on to form a product, \\(P\\), with the release of the enzyme, i.e. \\[\nS+E  \\xrightleftharpoons[k_{-1}]{k_{1}}  C \\xrightarrow{k_2} P+E .\n\\]\n\n5.2.1 Deriving the model equations\nFor notational convenience we let lower case letter denote concentrations, i.e. \n\\[\ns(t)=[S](t),  \\ \\ c(t)=[C](t) , \\\\ e(t)=[E](t), \\\\ p(t)=[P](t).\n\\]\nApplying the law of mass action the above enzyme kinetic scheme can be described by the system of ODES\n\\[\n\\begin{aligned}\n\\frac{d s}{dt} &= -k_1 se + k_{-1}c, \\nonumber \\\\\n\\frac{d e}{dt} &= -k_1 se + k_{-1}c +k_2 c,  \\nonumber\\\\\n\\frac{d c}{dt} &= k_1 se - k_{-1}c-k_2c, \\nonumber \\\\\n\\frac{d p}{dt} &= k_2 c.\n\\end{aligned}\n\\tag{5.1}\\]\nWe consider initial conditions such that at \\(t=0\\) the reaction has not yet started, i.e. there is no product or complex formed \\[\ns(0)=s_0, \\ \\ e(0)=e_0, \\ \\ c(0)=0, \\ \\ p(0)=0,\n\\] where \\(s_0\\) and \\(e_0\\) represent the initial concentrations of substrate and enzyme, respectively.\n\n\n5.2.2 Numerical solutions\nIn Figure 5.1 we plot numerical solutions of Equation 5.1. For this solution we have chosen initial conditions such that \\[\n\\frac{e_0}{s_0}\\ll 1.\n\\] Note that \\(c\\) and \\(e\\) evolve rapidly in time close to the initial data whilst those of \\(s\\) and \\(p\\) do not.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\nk_1=1.0\nk_2=0.4\nk_m_1=2.0\ns_0=10.0\ne_0=0.5\np_0=0\nc_0=0\n\ndef rhs_bruss_model(z,t):\n  rhs=np.zeros_like(z)\n  s=z[0]\n  e=z[1]\n  c=z[2]\n  p=z[3]\n\n  ds_dt= -k_1*s*e + k_m_1*c\n  de_dt= -k_1*s*e + k_m_1*c + k_2*c\n  dc_dt= k_1*s*e  - k_m_1*c - k_2*c\n  dp_dt= k_2*c\n\n  rhs[0]=ds_dt\n  rhs[1]=de_dt\n  rhs[2]=dc_dt\n  rhs[3]=dp_dt\n  return rhs\n\nt = np.linspace(0, 100, 1000)\n\ninit_cond=[s_0,e_0,c_0,p_0]\nsol1 = odeint(rhs_bruss_model, init_cond,t)\n\n\ns=sol1[:,0]\ne=sol1[:,1]\nc=sol1[:,2]\np=sol1[:,3]\n\n\nfig, ax=plt.subplots(2,2)\nax[0,0].plot(t, s, 'b')\nax[0,0].set_xlabel('$t$')\nax[0,0].set_ylabel('$s$')\n\nax[0,1].plot(t,c,'r',t,e,'k')\nax[0,1].set_xlabel('$t$')\nax[0,1].legend(['$c$','$e$'])\n\nax[1,0].plot(t,p,'r')\nax[1,0].set_xlabel('$t$')\nax[1,0].set_ylabel('$p$')\n\nax[1,1].plot( s, c,'r')\nax[1,1].set_xlim([0,1.25*s_0])\nax[1,1].set_xlabel('$s$')\nax[1,1].set_ylabel('$c$')\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.1: Numerical solutions of the Michaelis Menten model\n\n\n\n\n\n\n5.2.3 Reducing the dimensions of the model\nWhilst there are four dependent variables in the problem (\\(s(t)\\), \\(c(t)\\), \\(e(t)\\) and \\(p(t)\\)), the description of the problem can be simplified by noting that the variable \\(p(t)\\) does not couple back to the other variables, i.e. if we can solve the system for \\(s(t)\\), \\(e(t)\\) and \\(c(t)\\) then \\(c(t)\\) can be expressed as a function of time and\n\\[\np(t)=k_2\\int c(t) dt + C_1.\n\\]\nFurthermore, there is a conserved quantity in the system. Note that\n\\[\n\\frac{d e}{dt}+\\frac{d c}{dt}=0,\n\\]\nwhich reflects the fact that enzyme exists either in free form or bound to the product. Integrating yields\n\\[\nc(t)+e(t)=C_2.\n\\]\nEvaluating at \\(t=0\\),\n\\[\ne_0=C_2.\n\\]\nHence\n\\[\nc(t)+e(t)=e_0\n\\]\nand the variable \\(e(t)\\) can be replaced by\n\\[\ne(t)=e_0-c(t)\n\\]\nGiven \\[\ne(t)=e_0-c(t),\n\\] substitute in \\[\n\\begin{aligned}\n\\frac{d s}{dt} &= -k_1 se + k_{-1}c, \\nonumber \\\\\n\\frac{d c}{dt} &= k_1 se - k_{-1}c-k_2c, \\nonumber \\\\\n\\end{aligned}\n\\] Hence \\[\n\\begin{aligned}\n\\frac{d s}{dt} &= -k_1 s(e_0-c) + k_{-1}c, \\nonumber \\\\\n\\frac{d c}{dt} &= k_1 s(e_0-c) - (k_{-1}+k_2)c, \\nonumber \\\\\n\\end{aligned}\n\\]\n\n\n5.2.4 The quasi-steady state approximation (QSSA)\nA usual approach to these equations is to assume that the timescale of complex dynamics is very fast compared to that of substrate dynamics.\nTo make the QSSA we assume that one of the variables (in this case \\(c\\)), is in equilibrium\n\\[\ndc/dt \\sim 0.\n\\]\nIn which case the second equation yields\n\\[\nc=\\frac{e_0s(t)}{s(t)+K_m},\n\\]\nwhere\n\\[\nK_m=\\frac{k_{-1}+k_2}{k_1},\n\\]\nis known as the Michaelis constant.\nNow consider \\[\n\\begin{aligned}\n\\frac{d s}{dt} &= -k_1 s(e_0-c) + k_{-1}c, \\nonumber \\\\\n\\end{aligned}\n\\] By QSSA \\[\n-k_1 s(e_0-c) + k_{-1}c=-k_2c=-k_2\\frac{e_0s(t)}{s(t)+K_m},\n\\] Hence \\[\n\\begin{aligned}\n\\frac{d s}{dt} &= -k_2\\frac{e_0s(t)}{s(t)+K_m}, \\nonumber \\\\\n\\end{aligned}\n\\] Note this could be achieved by direct substitution for \\(c(t)\\).\n\n\n5.2.5 Enzyme kinetics: the Michaelis-Menten quasi-steady state approximation (QSSA)\n\n5.2.5.1 Nondimensionalisation\nNondimensionalisation using \\[\n\\tau=k_1 e_0 t, \\ \\ \\ u=\\frac{s}{s_0}, \\ \\ \\ v=\\frac{c}{e_0},\n\\] yields the ODEs \\[\n\\begin{aligned}\n\\frac{d u}{d\\tau} &= -u+(u+K-\\lambda)v, \\nonumber \\\\\n\\epsilon \\frac{d v}{d\\tau} &= u-(u+K)v, \\nonumber \\\\\n\\end{aligned}\n\\tag{5.2}\\]\nwhere \\[\n\\lambda=\\frac{k_2}{k_1 s_0}, \\ \\ \\ K=\\frac{k_{-1}+k_2}{k_1 s_0}, \\ \\ \\ \\epsilon=\\frac{e_0}{s_0}.\n\\]\n\n\n5.2.5.2 Asymptotic expansions: the outer solution\nWe consider the (often realised) case where the amount of enzyme in the system is small compared with the amount of substrate, i.e. \\[\n\\epsilon \\ll 1.\n\\] The presence of the small parameter \\(\\epsilon\\) allows us to use perturbation theory to calculate approximate solutions to Equation 5.2. However, the problem is singular owing to the \\(\\epsilon dv/dt\\) term.\nWe propose an outer solution of the form\n\\[\n\\begin{aligned}\nu(\\tau;\\epsilon)=u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ... = \\sum_{n=0}^{\\infty}u_n(\\tau)\\epsilon^n, \\nonumber \\\\\nv(\\tau;\\epsilon)=v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ... = \\sum_{n=0}^{\\infty}v_n(\\tau)\\epsilon^n.  \\nonumber  \n\\end{aligned}\n\\]\nSubstituting the expansions in Equation 5.2 yields\n\\[\n\\begin{aligned}\n\\frac{du_0}{d\\tau} + \\epsilon \\frac{du_1}{d\\tau} + \\epsilon^2\\frac{du_2}{d\\tau} + ... = -(u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...)+  \\nonumber \\\\ (u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...+ K-\\lambda)(v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ...).  \\nonumber\n\\end{aligned}\n\\]\nGathering terms as coefficients of the different powers of \\(\\epsilon\\) yields\n\\[\n\\begin{aligned}\n\\frac{du_0}{d\\tau} + \\epsilon \\frac{du_1}{d\\tau} + ... = -u_0(\\tau)+ (u_0(\\tau)+ K-\\lambda)v_0  +\\epsilon (-u_1(\\tau) + u_1v_0+v_1u_0+v_1(K-\\lambda)) + O(\\epsilon^2), \\nonumber\n\\end{aligned}\n\\]\nwhere terms of order \\(\\epsilon^2\\) have been neglected.\nConsidering the \\(v\\) equation yields\n\\[\n\\begin{aligned}\n\\epsilon(\\frac{dv_0}{d\\tau} + \\epsilon \\frac{dv_1}{d\\tau} + \\epsilon^2\\frac{dv_2}{d\\tau} + ..) = u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...  \\nonumber \\\\ -(u_0(\\tau) + \\epsilon u_1(\\tau) + \\epsilon^2 u_2(\\tau) + ...+ K) (v_0(\\tau) + \\epsilon v_1(\\tau) + \\epsilon^2 v_2(\\tau) + ...).  \\nonumber\n\\end{aligned}\n\\]\nGathering terms as coefficients of the different powers of \\(\\epsilon\\) yields\n\\[\n\\begin{aligned}\n\\epsilon\\frac{dv_0}{d\\tau} + \\epsilon^2 \\frac{dv_1}{d\\tau} + ... = u_0(\\tau)-   u_0(\\tau)v_0(\\tau) -v_0 K  \\nonumber \\\\ +\\epsilon (u_1(\\tau) - u_0v_1 - u_1v_0 - Kv_1) + O(\\epsilon^2).  \\nonumber\n\\end{aligned}\n\\]\nAt \\(O(1)\\)\n\\[\n\\begin{aligned}\n\\frac{du_0}{d\\tau} = -u_0+ (u_0+ K-\\lambda)v_0  \\nonumber \\\\\n0= u_0 - u_0 v_0 -v_0K.    \\nonumber\n\\end{aligned}\n\\]\nSolving the algebraic equation yields\n\\[\nv_0=\\frac{u_0}{u_0+K},\n\\]\nand substituting in the \\(u_0\\) equation yields\n\\[\n\\frac{du_0}{d\\tau} = -u_0+ (u_0+ K-\\lambda)\\frac{u_0}{u_0+K} = -\\frac{\\lambda u_0}{u_0+K}.\n\\]\nIntegrating yields\n\\[\nu_0+K\\ln u_0=-\\lambda \\tau +A,\n\\]\nwhere \\(A\\) is an integration constant.\nWhen posing a solution as an expansion, a necessary question to ask is when the expansion is a valid? On the outer scale we have shown that \\[\nv_0=\\frac{u_0}{u_0+K}.\n\\]\nNote that the expression\n\\[\nv_0=\\frac{u_0}{u_0+K}\n\\]\ndoes not satisfy the initial condition \\(v(0)=0\\). As \\(u_0(0)=1\\), we find that at \\(\\tau=0\\)\n\\[\nv_0=\\frac{1}{1+K} \\neq 0.\n\\]\nHence the proposed expansion is not valid at least near \\(\\tau=0\\).\n\n\n5.2.5.3 Asymptotic expansions: the inner solution\nThis issue can be rectified by proposing a different scaling for time and recalculating a series solution in the new coordinate system.\nWe proceed by making the change of variable \\[\n\\sigma=\\frac{\\tau}{\\epsilon}.\n\\]\nNote that \\(\\sigma=1\\) corresponds to \\(\\tau=\\epsilon\\). Hence the proposed rescaling of time will give rise to what is called the inner solution to the problem (close to \\(t=0\\)).\nTo distinguish inner and outer solutions we relabel dependent variables such that\n\\[\n\\begin{aligned}\nu(\\tau;\\epsilon)=U(\\sigma;\\epsilon),  \\nonumber \\\\\nv(\\tau;\\epsilon)=V(\\sigma;\\epsilon). \\nonumber\n\\end{aligned}\n\\]\nNote that \\[\n\\frac{d}{d\\tau}=\\frac{1}{\\epsilon}\\frac{d}{d\\sigma}.\n\\] Hence upon changing variables \\[\n\\begin{aligned}\n\\frac{1}{\\epsilon}\\frac{d U}{d\\sigma} &= -\\epsilon U+ \\epsilon (U+K-\\lambda)V, \\nonumber \\\\\n\\frac{1}{\\epsilon}\\ \\epsilon \\frac{d V}{d\\sigma} &= U-(U+K)V.  \n\\end{aligned}\n\\]\nUpon tidying \\[\n\\begin{aligned}\n\\frac{d U}{d\\sigma} &= -\\epsilon U+ \\epsilon (U+K-\\lambda)V, \\nonumber \\\\\n\\frac{d V}{d\\sigma} &= U-(U+K)V.  \n\\end{aligned}\n\\tag{5.3}\\]\nWe seek series solutions to Equation 5.3 of the form\n\\[\n\\begin{aligned}\nU(\\sigma;\\epsilon)&=U_0(\\sigma) + \\epsilon U_1(\\sigma) + \\epsilon^2 U_2(\\sigma) + ... = \\sum_{n=0}^{\\infty}U_n(\\sigma)\\epsilon^n, \\nonumber \\\\\nV(\\sigma;\\epsilon)&=V_0(\\sigma) + \\epsilon V_1(\\sigma) + \\epsilon^2 V_2(\\sigma) + ... = \\sum_{n=0}^{\\infty}V_n(\\sigma)\\epsilon^n. \\nonumber  \n\\end{aligned}\n\\]\nSubstitution yields \\[\n\\begin{aligned}\n\\frac{dU_0}{d\\sigma}+ \\epsilon\\frac{dU_1}{d\\sigma}+ ..... &= \\epsilon\\left( U_0+\\epsilon U_1 + ... + (U_0+\\epsilon U_1+ +K-\\lambda)(V_0+\\epsilon V_1+...)\\right) \\\\\n\\frac{dV_0}{d\\sigma}+ \\epsilon\\frac{dV_1}{d\\sigma}+ ..... &= (U_0+\\epsilon U_1+...)-(U_0+\\epsilon U_1+...+K)(V_0+\\epsilon V_1+...).\n\\end{aligned}\n\\]\nHence at leading order \\[\n\\begin{aligned}\n\\frac{dU_0}{d\\sigma}&=0  \\nonumber\\\\\n\\frac{dV_0}{d\\sigma}&=U_0-(U_0+K)V_0.\n\\end{aligned}\n\\]\nGiven the initial condition \\(U(0)=1\\) we obtain that the inner solution is\n\\[\nU(\\sigma)=1.\n\\]\nSubstituting in the second equation gives\n\\[\n\\frac{dV_0}{d\\sigma}=1-(1+K)V_0.\n\\]\nGiven \\(V_0(0)=0\\) we obtain\n\\[\nV_0=\\frac{1-e^{-(1+K)\\sigma}}{1+K}.\n\\]\n\n\n5.2.5.4 Asymptotic expansions: matching the inner and outer solutions\nInner and outer solutions are matched by taking limits \\[\n\\lim_{\\tau \\rightarrow 0}(u_0(\\tau),v_0(\\tau))=\\lim_{\\sigma \\rightarrow \\infty}(U_0(\\sigma),V_0(\\sigma)).\n\\]\nNote that\n\\[\n\\lim_{\\sigma\\rightarrow \\infty} V_0(\\sigma)= \\lim_{\\sigma\\rightarrow \\infty}  \\frac{1-e^{-(1+K)\\sigma}}{1+K} = \\frac{1}{1+K},\n\\]\nand\n\\[\n\\lim_{\\tau\\rightarrow 0}(v_0(\\tau)) =\\lim_{\\tau\\rightarrow 0}\\frac{u_0}{u_0+K} =  \\frac{1}{1+K}.\n\\]\nHence the \\(v\\) variables are already matching in the appropriate limit.\nSimilarly\n\\[\n\\lim_{\\sigma\\rightarrow \\infty} U_0(\\sigma)= 1,\n\\]\nhence we require that\n\\[\n\\lim_{\\tau \\rightarrow 0} u_0(\\tau)= 1.\n\\]\nHence for\n\\[\n(u_0+K\\ln u_0=-\\lambda \\tau +A)\n\\]\nto hold as \\(\\tau \\rightarrow 0\\) implies \\(A=1\\)."
  },
  {
    "objectID": "enzymekinetics.html#the-brusselator",
    "href": "enzymekinetics.html#the-brusselator",
    "title": "5  Biochemical kinetics",
    "section": "5.3 The Brusselator",
    "text": "5.3 The Brusselator\nThe Brusselator is an abstract model that can be used to demonstrate oscillations in (bio)-chemical systems. Consider a chemical reaction where five chemical species, A, B, D, X and Y, react according to the scheme \\[\n\\begin{aligned}\nA&\\xrightarrow{k_{1}} X,  \\nonumber \\\\\nB+X&\\xrightarrow{k_{2}} Y+D, \\nonumber\\\\\n2X+Y&\\xrightarrow{k_{3}} 3X, \\nonumber\\\\\nX&\\xrightarrow{k_{4}} E.\n\\end{aligned}\n\\]\nAssuming that the concentration of A and B (\\([A]\\) and \\([B]\\), respectively) are in vast excess (i.e. the amount that A and B get depleted by the reactions is negligible compared with the total amount of A and B present), their concentration are treated as constants. Furthermore, as D and E are products but not reactants (they only appear on the right-hand side of reactions) we do not concern ourselves with their dynamics.\n\n5.3.1 Deriving model equations\nTo make the steps leading to ODEs obvious, it is useful to rewrite the reaction scheme in the form \\[\n\\begin{aligned}\nA&\\xrightarrow{k_{1}} X,  \\nonumber \\\\\nB+X&\\xrightarrow{k_{2}} Y+D, \\nonumber\\\\\nX+X+Y&\\xrightarrow{k_{3}} X+X+X, \\nonumber\\\\\nX&\\xrightarrow{k_{4}} E.\n\\end{aligned}\n\\]\nApplying the law of mass action yields that the four reactions occur at rates:\n\n\\(k_1[A]\\),\n\\(k_2[B][X]\\),\n\\(k_3[X]^2[Y]\\),\n\\(k_4[X]\\).\n\nThe total time derivative of \\([X]\\) is obtained by visiting each X in the reaction scheme once and adding the corresponding reaction rate to the right-hand side of the ODE, i.e.\n\\[  \n\\begin{aligned}\n\\frac{d[X]}{dt} &= \\overbrace{k_1[A]}^{R1-lhs} - \\overbrace{k_2[B][X]}^{R2-lhs} -  \\overbrace{k_3[X]^2[Y]}^{R3-lhs} - \\overbrace{k_3[X]^2[Y]}^{R3-lhs} + \\overbrace{k_3[X]^2[Y]}^{R3-rhs}+ \\overbrace{k_3[X]^2[Y]}^{R3-rhs}+ \\overbrace{k_3[X]^2[Y]}^{R3-rhs} -\\overbrace{k_4[X]}^{R4-lhs}, \\nonumber \\\\\n        &= k_1[A] - k_2[B][X] + k_3[X]^2[Y]   -k_4[X].\n\\end{aligned}\n\\]\nSimilarly for species Y we obtain that the total rate of change in time is \\[\n\\begin{aligned}\n  \\frac{d[Y]}{dt}=k_2[B][X]-k_3[X]^2[Y].\n\\end{aligned}\n\\]\n\n\n5.3.2 Nondimensionalisation\nUpon making the change of variables \\[\n\\begin{aligned}\nx=\\sqrt{\\frac{k_3}{k_4}}[X], \\ \\ \\ \\ \\ y=\\sqrt{\\frac{k_3}{k_4}}[Y], \\ \\ \\textrm{and} \\ \\ \\tau=k_4 t,\n\\end{aligned}\n\\] yields \\[\n\\begin{aligned}\n\\frac{d x}{d \\tau} &= a-bx+x^2y-x = f(x,y), \\\\\n\\frac{d y}{d \\tau} &= bx-x^2y = g(x,y),\n\\end{aligned}\n\\tag{5.4}\\]\nwhere \\[\na=[A]\\frac{k_1}{k_4}\\sqrt{\\frac{k_3}{k_4}} \\ \\ \\ \\textrm{and} \\ \\ \\ b= [B]\\frac{k_2}{k_4}.\n\\]\n\n\n5.3.3 Steady states analysis\nSeeking steady states \\((x^*,y^*)\\) of equations Equation 5.4 such that \\[\nf(x^*,y^*)=g(x^*,y^*)=0\n\\] yields\n\\[\n(x^*,y^*)=(a,\\frac{b}{a}).\n\\]\n\n\n5.3.4 Linear stability analysis\nThe Jacobian matrix is\n\\[\nA=\\left(\\begin{array}{rr}\n\\frac{\\partial f}{\\partial x}&\\frac{\\partial f}{\\partial y} \\\\ \\frac{\\partial g}{\\partial x }&\\frac{\\partial g}{\\partial y} \\end{array}\\right) = \\left(\\begin{array}{rr}\n-b+2xy-1&x^2\\\\ b-2xy &-x^2\\end{array}\\right).\n\\]\nEvaluating the Jacobian at \\((a,b/a)\\) yields\n\\[\nA=\n\\left(\\begin{array}{rr}\nb-1&a^2\\\\ -b &-a^2\\end{array}\\right).\n\\]\nThe determinant of the Jacobian is\n\\[\n\\det{A}=-(b-1)a^2+a^2b=a^2&gt;0,\n\\]\nHence \\((a,b/a)\\) is not a saddle. The trace of the Jacobian is \\[\n\\mathrm{tr} A=b-1-a^2.\n\\]\nHence if \\(b&gt;1+a^2\\) the trace is positive and, referring to Figure 4.1, the steady state is linearly unstable. Otherwise, the steady state is linearly stable.\nIn Figure 5.2 we numerically solve Equation 5.4 in the case of oscillatory solutions. Note that when the steady state is unstable, the numerical solution indicates that the system has limit cycle solutions. A valid question to ask is whether one can prove that this is the case.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\na=1.0\nb=3.2\n\ndef rhs_bruss_model(z,t):\n  rhs=np.zeros_like(z)\n  x=z[0]\n  y=z[1]\n  dx_dt=a-b*x+x**2*y-x\n  dy_dt=b*x-x**2*y\n  rhs[0]=dx_dt\n  rhs[1]=dy_dt\n  return rhs\n\nt = np.linspace(0, 50, 1000)\n\ninit_cond=[0.5,0.5]\nsol1 = odeint(rhs_bruss_model, init_cond,t)\n\n\nx=sol1[:,0]\ny=sol1[:,1]\n\nplt.plot(t, x, 'b',t,y,'r')\n\nplt.legend(['$x$','$y$'],loc='best')\nplt.xlabel('t')\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.2: Numerical solutions of the Brusselator model\n\n\n\n\n\n\n5.3.5 Applying the Poincaire-Bendixson theorem\nRecall that the Poincaire-Bendixson theorem can be used to prove the existence of limit cycle solutions in a case where a bounding set encloses a single unstable steady state. Hence given the case of the Brusselator with \\(b&gt;a^2+1\\), the identification of a bounding set will allow application of the Poincaire-Bendixson theorem and hence prove the existence of limit cycle solutions.\nWe begin by defining the nullclines of the system. The \\(x\\) nullcline is given by\n\\[\ny=\\frac{1+b}{x}-\\frac{a}{x^2}.\n\\]\nThe \\(y\\) nullclines are given by\n\\[\ny=\\frac{b}{x} \\ \\ \\ \\textrm{and} \\ \\ \\ x=0.\n\\]\nIn the positive quadrant, this nullcline has a single root at \\(a/(1+b)\\), tends to 0 as \\(x\\rightarrow \\infty\\) and has a maximum at \\(x=2a/(1+b)\\).\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\n\nx_vec=np.linspace(0.01,6,100)\n\ndef ComputeCompetitionSol(a,b,x_vec):\n    t = np.linspace(0, 10, 1000)\n\n    init_cond1=[0.75,0.75]\n    init_cond2=[4.55,4.15]\n    init_cond3=[2.5,0.5]\n\n    ss=[a,b/a]\n\n    alpha=2.0\n    sol1 = odeint(rhs_bruss_model, init_cond1,t)\n    sol2 = odeint(rhs_bruss_model, init_cond2,t)\n    sol3 = odeint(rhs_bruss_model, init_cond3,t)\n\n\n\n  \n    x_ncline=(1+b)/x_vec-a/x_vec**2\n    y_ncline_1_a=[0,0]    \n    y_ncline_1_b=[0,5]   \n    y_ncline_2_x=b/x_vec\n\n    return sol1,sol2,sol3,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x\n\na=1.0\nb=3.2\nsol1,sol2,sol3,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x=ComputeCompetitionSol(a,b,x_vec)\n\n\n\nfig, ax = plt.subplots(1,2)\nax[0].plot(x_vec,x_ncline,'k--')\nax[0].plot(y_ncline_1_a,y_ncline_1_b,'k--')\nax[0].plot(x_vec,y_ncline_2_x,'r--')\n\nax[0].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[0].plot(ss[0],ss[1],'k*')\nplt.xlabel('$x$')\nplt.ylabel('$y$')\n\nax[0].set_xlim([-0.05,6])\nax[0].set_ylim([-0.005,6])\n\n\na=4.0\nb=3.2\n\nsol1,sol2,sol3,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x=ComputeCompetitionSol(a,b,x_vec)\n\nax[1].plot(x_vec,x_ncline,'k--')\nax[1].plot(y_ncline_1_a,y_ncline_1_b,'k--')\nax[1].plot(x_vec,y_ncline_2_x,'r--')\n\nax[1].plot(sol1[:,0],sol1[:,1],sol2[:,0],sol2[:,1],sol3[:,0],sol3[:,1])\nax[1].plot(ss[0],ss[1],'k*')\nplt.xlabel('$x$')\nplt.ylabel('$y$')\n\nax[1].set_xlim([-0.05,6])\nax[1].set_ylim([-0.005,6])\nsol1,sol2,sol3,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x=ComputeCompetitionSol(a,b,x_vec)\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.3: Numerical solution of the Brusselator.\n\n\n\n\nIn Figure 5.3 we plot the the oscillatory solution together with the nullclines. Note that the nullclines separate the phase plane into regions of constant sign. Note that the \\(x\\) nullcline separates the phase plane into regions where \\(dx/dt&gt;0\\) and \\(dx/dt&lt;0\\). Similarly, the \\(y\\) nullcline separates the phase plane into regions where \\(dy/dt&gt;0\\) and \\(dy/dt&lt;0\\).\nNote that signs for \\(dx/dt\\) can be determined by considering behaviour of the function \\(f\\) as one moves away from the nullcline where, by definition, \\(f=0\\). Consider some point that sits on the x nullcline. While keeping the \\(x\\) value fixed, increase \\(y\\) so the point moves vertically in the phase plane. This implies that \\(f\\) has increased because the only term to change is \\(x^2y\\). Hence \\(f\\) increases upon increasing \\(y\\) and therefore \\(dx/dt\\) is positive for all points above the \\(x\\) nullcline. Alternatively, note that in the Jacobian matrix we have calculated that \\(\\partial f/\\partial y\\) is positive.\n\n5.3.5.1 A confined set\nTo define a confined set, we construct the closed loop ABCDEA in phase space (see Figure 5.4) where the points A, B, C, D and E are defined as follows. Let the points A and B be two points on the \\(x\\) axis with coordinates \\[\n(\\delta,0)\n\\] and \\[\n\\left(\\frac{a}{1+b},0\\right).\n\\] respectively. We choose \\(\\delta&gt;a\\). The outward normal to the line segment AB is \\(\\mathbf{n}=[0,-1]\\). To show that the trajectories point inwards along AB, we compute\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] = -\\frac{dy}{dt}.\n\\]\nAs the line segment AB sits below the \\(y\\) nullcline, \\(dy/dt&gt;0\\) in this region. Hence\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] = -\\frac{dy}{dt}&lt;0.\n\\]\nHence trajectories point inwards on the line segment AB.\nLet \\(C\\) represent the point \\[\n\\left(\\frac{a}{1+b},b\\frac{1+b}{a}\\right).\n\\]\nThe normal vector to the line segment BC is \\(\\mathbf{n}=[-1,0]\\). As BC lies to the left of the \\(x\\) nullcline, in a region where \\(dx/dt&gt;0\\), then\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] = -\\frac{dx}{dt}&lt;0.\n\\]\nHence trajectories point inwards on the line segment BC.\nConsider the line segment CD where D has coordinates \\[\n\\left(k,b\\frac{1+b}{a}\\right),\n\\] with \\(k&gt;a\\)\nThe normal to this line segment is [0,1]. As CD lies in a region of the phase plane where \\(dy/dt&lt;0\\),\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] = \\frac{dy}{dt}&lt;0.\n\\] Hence trajectories point inwards on the line segment CD.\nLet E be a point that sits on the \\(x\\) nullcline at some position \\[\n\\left(\\delta,\\frac{\\delta(1+b)-a}{\\delta^2}\\right),\n\\] such that DE is a straight line with outwardly pointing normal vector \\([1,1]\\). Along DE\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] =   a-bx+x^2y-x + bx-x^2y = a-x&lt;0\n\\]\nfor \\(x&gt;a\\). As \\(k&gt;a\\), \\(x&gt;a\\) for all points on DE, hence trajectories point inwards on DE.\nFinally, consider the line segment EA which has normal vector \\(\\mathbf{n}=[1,0]\\). As \\(dx/dt&lt;0\\) along EA\n\\[\n\\mathbf{n}.\\left[\\frac{dx}{dt},\\frac{dy}{dt}\\right] =  \\frac{dx}{dt} &lt;0.\n\\]\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy\nfrom scipy.integrate import odeint\n\n\n\nx_vec=np.linspace(0.01,6,100)\n\ndef ComputeCompetitionSol(a,b,x_vec):\n    t = np.linspace(0, 10, 1000)\n\n    init_cond1=[0.75,0.75]\n    init_cond2=[4.55,4.15]\n    init_cond3=[2.5,0.5]\n\n    ss=[a,b/a]\n\n    alpha=2.0\n    sol1 = odeint(rhs_bruss_model, init_cond1,t)\n    \n\n\n  \n    x_ncline=(1+b)/x_vec-a/x_vec**2\n    y_ncline_1_a=[0,0]    \n    y_ncline_1_b=[0,5]   \n    y_ncline_2_x=b/x_vec\n\n    return sol1,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x\n\na=1.0\nb=3.2\nsol1,ss,x_ncline,y_ncline_1_a,y_ncline_1_b,y_ncline_2_x=ComputeCompetitionSol(a,b,x_vec)\n\n\nk=2*a\ndelta=5.5\n\nA=[delta,0]\nB=[1/(1+b),0]\nC=[a/(1+b),b*(1+b)/a]\nD=[k,b*(1+b)/a]\nE=[delta,(delta*(1+b)-a)/delta**2]\n\n\nfig, ax = plt.subplots()\nax.plot(x_vec,x_ncline,'k--')\nax.plot(y_ncline_1_a,y_ncline_1_b,'k--')\nax.plot(x_vec,y_ncline_2_x,'r--')\n\nax.plot(sol1[:,0],sol1[:,1])\nax.plot(ss[0],ss[1],'k*')\nax.plot([A[0], B[0]],[A[1], B[1]],'m--')\nax.plot([B[0], C[0]],[B[1], C[1]],'m--')\nax.plot([C[0], D[0]],[C[1], D[1]],'m--')\nax.plot([D[0], E[0]],[D[1], E[1]],'m--')\nax.plot([E[0], A[0]],[E[1], A[1]],'m--')\n\nax.annotate('A', A)\nax.annotate('B', B)\nax.annotate('C', C)\nax.annotate('D', D)\nax.annotate('E', E)\n\n\nplt.xlabel('$x$')\nplt.ylabel('$y$')\n\nax.set_xlim([-0.05,6])\nax.set_ylim([-0.5,20])\n\n\nplt.grid()\nplt.show()\n\n\n\n\n\nFigure 5.4: Numerical solution of the Brusselator.\n\n\n\n\nHence at all points on the closed loop ABCDEA trajectories point inwards (see Figure 5.4). Hence ABDCEA is a confined set and the Poincaire-Bendixson theorem states that the system exhibits limit cycle solutions when the steady state is unstable. This is precisely the behaviour that we see numerically in Figure Figure 5.3."
  },
  {
    "objectID": "PythonAppendix.html#symbolic-calculations",
    "href": "PythonAppendix.html#symbolic-calculations",
    "title": "6  Python",
    "section": "6.1 Symbolic calculations",
    "text": "6.1 Symbolic calculations\nSymbolic calculations ahve been performed using the Python library Sympy.\nThis library comes with tutorials.\nYou are encouraged to familiarise yourself with the syntax by working through some of the tutorial examples provided at the links above.\nMany of the calculations that we do throughout the course involve solving systems of algebraic equations"
  },
  {
    "objectID": "PythonAppendix.html#numerical-solution-of-difference-equations",
    "href": "PythonAppendix.html#numerical-solution-of-difference-equations",
    "title": "6  Python",
    "section": "6.2 Numerical solution of difference equations",
    "text": "6.2 Numerical solution of difference equations\nDifference equations have been solved using a for loop. Routinse have been written to solve either single or coupled system of difference equaitons."
  },
  {
    "objectID": "PythonAppendix.html#numerical-integration-of-odes",
    "href": "PythonAppendix.html#numerical-integration-of-odes",
    "title": "6  Python",
    "section": "6.3 Numerical integration of ODEs",
    "text": "6.3 Numerical integration of ODEs\nThroughout the notes systems of ODEs have been integrated using the Scipy function odeint."
  },
  {
    "objectID": "PythonAppendix.html#plotting",
    "href": "PythonAppendix.html#plotting",
    "title": "6  Python",
    "section": "6.4 Plotting",
    "text": "6.4 Plotting\nLine graphs are plotted using the Python library Matplotlib."
  }
]